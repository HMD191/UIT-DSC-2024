{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9571267,"sourceType":"datasetVersion","datasetId":5834049},{"sourceId":9660707,"sourceType":"datasetVersion","datasetId":5902254}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries and Load Dataset","metadata":{}},{"cell_type":"code","source":"%%capture\n#!git clone https://github.com/huggingface/transformers.git\n!pip install datasets evaluate transformers[sentencepiece]\n!pip install rouge_score\n!pip install underthesea\n!pip install pyvi\n!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:28:29.401988Z","iopub.execute_input":"2024-10-23T15:28:29.402335Z","iopub.status.idle":"2024-10-23T15:29:34.939502Z","shell.execute_reply.started":"2024-10-23T15:28:29.402286Z","shell.execute_reply":"2024-10-23T15:29:34.938289Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#%%capture\n\nimport gdown\n\n!gdown 1jWDnP1xF01_pmeJYsRHxSVBkLZ0I9LAt #utils T5 for VQA","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:29:34.940868Z","iopub.execute_input":"2024-10-23T15:29:34.941175Z","iopub.status.idle":"2024-10-23T15:29:41.314876Z","shell.execute_reply.started":"2024-10-23T15:29:34.941149Z","shell.execute_reply":"2024-10-23T15:29:41.313733Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1jWDnP1xF01_pmeJYsRHxSVBkLZ0I9LAt\nFrom (redirected): https://drive.google.com/uc?id=1jWDnP1xF01_pmeJYsRHxSVBkLZ0I9LAt&confirm=t&uuid=812ae51d-c3dc-490d-8df5-b23117e87785\nTo: /kaggle/working/utils.py\n100%|████████████████████████████████████████| 109k/109k [00:00<00:00, 93.6MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from PIL import Image\n\nimport requests\n\nimport os\nimport shutil\nimport torch\n\nfrom urllib.request import urlopen\nfrom PIL import Image\nimport timm\nimport tqdm\nimport torch\nfrom IPython.display import FileLink","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:29:41.316194Z","iopub.execute_input":"2024-10-23T15:29:41.316849Z","iopub.status.idle":"2024-10-23T15:29:45.725098Z","shell.execute_reply.started":"2024-10-23T15:29:41.316821Z","shell.execute_reply":"2024-10-23T15:29:45.724271Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import json\n\ntrain_json = json.load(open('/kaggle/input/dsc24-vimmsd/vimmsd-train.json'))\ndev_json = json.load(open('/kaggle/input/dsc24-vimmsd/vimmsd-public-test.json'))","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:29:45.728238Z","iopub.execute_input":"2024-10-23T15:29:45.728933Z","iopub.status.idle":"2024-10-23T15:29:45.923715Z","shell.execute_reply.started":"2024-10-23T15:29:45.728903Z","shell.execute_reply":"2024-10-23T15:29:45.922836Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Image feature extraction","metadata":{}},{"cell_type":"code","source":"# images = []\n\n# for key, item in train_json.items():\n#     images.append(item['image'])\n\n# for key, item in dev_json.items():\n#     images.append(item['image'])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:29:45.924879Z","iopub.execute_input":"2024-10-23T15:29:45.925239Z","iopub.status.idle":"2024-10-23T15:29:45.929684Z","shell.execute_reply.started":"2024-10-23T15:29:45.925207Z","shell.execute_reply":"2024-10-23T15:29:45.928721Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# source_all = ['/kaggle/input/dsc24-vimmsd/dev-images/dev-images',\n#               '/kaggle/input/dsc24-vimmsd/train-images/train-images']\n\n# destination = './images'\n# #os.mkdir(destination)\n\n# for source in source_all:\n#     allfiles = os.listdir(source)\n#     for f in allfiles:\n#         src_path = os.path.join(source, f)\n#         dst_path = os.path.join(destination, f)\n#         shutil.copy(src_path, dst_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:29:45.930903Z","iopub.execute_input":"2024-10-23T15:29:45.931177Z","iopub.status.idle":"2024-10-23T15:29:45.938360Z","shell.execute_reply.started":"2024-10-23T15:29:45.931153Z","shell.execute_reply":"2024-10-23T15:29:45.937558Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## BEiT","metadata":{}},{"cell_type":"code","source":"# model = timm.create_model(\n#     'beitv2_base_patch16_224.in1k_ft_in22k_in1k',\n#     pretrained=True,\n#     num_classes=0,  # remove classifier nn.Linear\n# ).to('cuda')\n\n# model = model.eval()\n# data_config = timm.data.resolve_model_data_config(model)\n# transforms = timm.data.create_transform(**data_config, is_training=False)\n\n# img_w = {}\n\n# def batch(iterable, n=1):\n#     l = len(iterable)\n#     for ndx in range(0, l, n):\n#         yield iterable[ndx:min(ndx + n, l)]","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:29:45.939572Z","iopub.execute_input":"2024-10-23T15:29:45.939981Z","iopub.status.idle":"2024-10-23T15:29:45.947492Z","shell.execute_reply.started":"2024-10-23T15:29:45.939945Z","shell.execute_reply":"2024-10-23T15:29:45.946715Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# p = '/kaggle/working/images/'\n\n# img_w = {}\n\n# # get features for images, we will do this 3 images at a time to reduce time\n\n# for x in tqdm.notebook.tqdm(batch(images, 3),total=int(len(images)/3)):\n#     img = [Image.open(p + v).convert('RGB') for v in x]\n#     print(x)\n\n#     with torch.no_grad():\n#         img  = torch.stack([transforms(i) for i in img]).to('cuda')\n#         output = model.forward_features(img)[:,1:,:]\n\n#     tmp_img_w = {k:v for k,v in zip(x,output)}\n\n#     img_w.update(tmp_img_w)\n\n#     del output\n#     del tmp_img_w\n#     del img\n#     torch.cuda.empty_cache()\n\n# torch.save(img_w, '/kaggle/working/beitv2-b-p.pt') # export for later used\n# FileLink('/kaggle/working/beitv2-b-p.pt')","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:29:45.948705Z","iopub.execute_input":"2024-10-23T15:29:45.949062Z","iopub.status.idle":"2024-10-23T15:29:45.957708Z","shell.execute_reply.started":"2024-10-23T15:29:45.949030Z","shell.execute_reply":"2024-10-23T15:29:45.956808Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Load extracted image features","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.nn.functional import normalize\n\nimg_w = torch.load('/kaggle/input/lovecat-beitv2-b-p/beitv2-b-p.pt') # already-saved features\nlen(img_w)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:29:45.958851Z","iopub.execute_input":"2024-10-23T15:29:45.959104Z","iopub.status.idle":"2024-10-23T15:31:12.034252Z","shell.execute_reply.started":"2024-10-23T15:29:45.959082Z","shell.execute_reply":"2024-10-23T15:31:12.033338Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"12218"},"metadata":{}}]},{"cell_type":"code","source":"img_w['ac7931bb887ad853b41675f07595bf04469970d1b099ffc8806a4ceaac7d7940.jpg'].shape","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:12.035410Z","iopub.execute_input":"2024-10-23T15:31:12.035684Z","iopub.status.idle":"2024-10-23T15:31:12.041629Z","shell.execute_reply.started":"2024-10-23T15:31:12.035661Z","shell.execute_reply":"2024-10-23T15:31:12.040737Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"torch.Size([196, 768])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\n\nfrom utils import T5ForConditionalGeneration\n\ntokenizer = T5Tokenizer.from_pretrained(\"VietAI/vit5-base\")\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"VietAI/vit5-base\").to('cuda')\n\nmodel.add_imgw(img_w)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:12.042962Z","iopub.execute_input":"2024-10-23T15:31:12.043233Z","iopub.status.idle":"2024-10-23T15:31:28.773152Z","shell.execute_reply.started":"2024-10-23T15:31:12.043210Z","shell.execute_reply":"2024-10-23T15:31:28.772290Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9c3c450bd41453eae8d0b7e3b62c321"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dda94287ede44d36b0523fed1ab0b747"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42586d621f174b6a81867974c00f9b8c"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e84bd5d95c546118da0e7571b2ef913"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/904M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a49027a033c1452f85afc0d56b0cf3e3"}},"metadata":{}},{"name":"stderr","text":"Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at VietAI/vit5-base and are newly initialized: ['resize_img_dim.bias', 'resize_img_dim.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Prepare datasets","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.DataFrame(train_json).T\ntest_df = pd.DataFrame(dev_json).T # public test","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:28.774321Z","iopub.execute_input":"2024-10-23T15:31:28.774913Z","iopub.status.idle":"2024-10-23T15:31:29.504084Z","shell.execute_reply.started":"2024-10-23T15:31:28.774884Z","shell.execute_reply":"2024-10-23T15:31:29.503307Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_df['image_id'] = train_df['image'].astype(str)\ntest_df['image_id'] = test_df['image'].astype(str)\n\ntrain_df['caption'] = train_df['caption'].astype(str)\ntest_df['caption'] = test_df['caption'].astype(str)\n\ntrain_df['label'] = train_df['label'].astype(str)\ntest_df['label'] = test_df['label'].astype(str)\n\n\n\ntrain_df['caption'] = train_df['caption'].str.lower()\ntest_df['caption'] = test_df['caption'].str.lower()\n\ntrain_df.drop(columns=['image'], inplace=True)\ntest_df.drop(columns=['image'], inplace=True)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:29.508603Z","iopub.execute_input":"2024-10-23T15:31:29.508931Z","iopub.status.idle":"2024-10-23T15:31:29.580862Z","shell.execute_reply.started":"2024-10-23T15:31:29.508903Z","shell.execute_reply":"2024-10-23T15:31:29.579993Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                             caption          label  \\\n0            cô ấy trên mạng vs cô ấy ngoài đời =)))  multi-sarcasm   \n1    người tâm linh giao tiếp với người thực tế :)))    not-sarcasm   \n2  hình như trăng hôm nay đẹp quá mọi người ạ! 😃 ...  multi-sarcasm   \n3  mọi người nghĩ sao về phát biểu của shark việt...    not-sarcasm   \n4        2 tay hai nàng chứ việc gì phải lệ hai hàng  multi-sarcasm   \n\n                                            image_id  \n0  8ae451edcd8ebf697f8763ece249115813149c55733bf8...  \n1  35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...  \n2  316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...  \n3  8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...  \n4  e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>label</th>\n      <th>image_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cô ấy trên mạng vs cô ấy ngoài đời =)))</td>\n      <td>multi-sarcasm</td>\n      <td>8ae451edcd8ebf697f8763ece249115813149c55733bf8...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>người tâm linh giao tiếp với người thực tế :)))</td>\n      <td>not-sarcasm</td>\n      <td>35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hình như trăng hôm nay đẹp quá mọi người ạ! 😃 ...</td>\n      <td>multi-sarcasm</td>\n      <td>316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mọi người nghĩ sao về phát biểu của shark việt...</td>\n      <td>not-sarcasm</td>\n      <td>8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2 tay hai nàng chứ việc gì phải lệ hai hàng</td>\n      <td>multi-sarcasm</td>\n      <td>e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nX = train_df.drop(columns=['label'])  # Features\ny = train_df['label']  # Labels\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n\ntrain_df = pd.concat([X_train, y_train], axis=1)\nval_df = pd.concat([X_test, y_test], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:29.582174Z","iopub.execute_input":"2024-10-23T15:31:29.582493Z","iopub.status.idle":"2024-10-23T15:31:29.967357Z","shell.execute_reply.started":"2024-10-23T15:31:29.582468Z","shell.execute_reply":"2024-10-23T15:31:29.966502Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape, val_df.shape, test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:29.968457Z","iopub.execute_input":"2024-10-23T15:31:29.968739Z","iopub.status.idle":"2024-10-23T15:31:29.973357Z","shell.execute_reply.started":"2024-10-23T15:31:29.968714Z","shell.execute_reply":"2024-10-23T15:31:29.972435Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"(9724, 3) (1081, 3) (1413, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, TrainingArguments, Seq2SeqTrainingArguments\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import DataLoader\n\ndef preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"inputs\"], max_length=400, truncation=True, padding=True\n    )\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"labels\"], max_length=32, truncation=True, padding=True\n        )\n    model_inputs['labels'] = labels['input_ids']\n    model_inputs['input_ids'] = model_inputs['input_ids']\n    model_inputs[\"image_id\"] = examples[\"image_id\"]\n    \n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:29.974712Z","iopub.execute_input":"2024-10-23T15:31:29.975069Z","iopub.status.idle":"2024-10-23T15:31:30.468222Z","shell.execute_reply.started":"2024-10-23T15:31:29.975037Z","shell.execute_reply":"2024-10-23T15:31:30.467405Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dict_obj = {}\n\ndict_obj['inputs'] = train_df['caption']\ndict_obj['labels'] =  train_df['label']\ndict_obj['image_id'] = train_df['image_id']\ntrain_dataset = Dataset.from_dict(dict_obj)\ntokenized_train_datasets = train_dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)\n\ndict_obj = {}\ndict_obj['inputs'] = val_df['caption']\ndict_obj['labels'] =  val_df['label']\ndict_obj['image_id'] = val_df['image_id']\nval_dataset = Dataset.from_dict(dict_obj)\ntokenized_val_datasets = val_dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:30.469302Z","iopub.execute_input":"2024-10-23T15:31:30.469938Z","iopub.status.idle":"2024-10-23T15:31:38.033207Z","shell.execute_reply.started":"2024-10-23T15:31:30.469909Z","shell.execute_reply":"2024-10-23T15:31:38.031827Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"         ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8404deab37b4abab05d6857ebcb148a"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf609b80db4b461db3f73eb45ea2cc48"}},"metadata":{}},{"name":"stdout","text":"   ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eab94ea129294401b1943e83cf4cbb9d"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67f8b044bfe542ac82a96f5c8085a0de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5a7759ec84a4f59aa9278301ac469af"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae7ea87b892844c5874c8ce8072fadb5"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0823e8ebca454f789a380cff871ab709"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"328ffeb2c2c44d958625cf62633490b1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"           ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e995897d897f4c0d85474567cb3d4a7a"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab776a8abdb74048a3987115955e201f"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95ded24e2df0473c8cde23595c74b5e2"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b00fc913924488584784508b9356704"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"818dcd032a6548bdb93ab8836e90537e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5586adfd9654f1cacb199f588666805"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"730b7257474c454baa7b43ccf13c907b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d2edcce55f1423d897bc556a8a36327"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\n\nimport numpy as np\n\nimport torch\n\ndef set_SEED():\n    SEED = 100\n    random.seed(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.enabled = False\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:38.035239Z","iopub.execute_input":"2024-10-23T15:31:38.035694Z","iopub.status.idle":"2024-10-23T15:31:38.043642Z","shell.execute_reply.started":"2024-10-23T15:31:38.035650Z","shell.execute_reply":"2024-10-23T15:31:38.042598Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import os\nfrom transformers.optimization import Adafactor, AdafactorSchedule\nfrom transformers import DataCollatorForSeq2Seq\nfrom utils import DataCollatorForSeq2Seq\n\nos.environ[\"WANDB_DISABLED\"] = \"True\"\nset_SEED()\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n\n#Adam\ntraining_args = Seq2SeqTrainingArguments(output_dir=\"./checkpoint\",\n                                      do_train=True,\n                                      do_eval=True,\n                                      num_train_epochs=1,\n                                      learning_rate=2.5e-5,\n                                      warmup_ratio=0.05,\n                                      weight_decay=0.01,\n                                      per_device_train_batch_size=8,\n                                      per_device_eval_batch_size=8,\n                                      logging_dir='./log',\n                                      group_by_length=True,\n                                      save_strategy=\"steps\",\n                                      evaluation_strategy=\"steps\",\n                                      save_total_limit=5,\n                                      eval_steps=100,\n                                      logging_steps = 100,\n                                      save_steps=100,\n                                      load_best_model_at_end= True,\n                                      fp16=True,\n                                      seed=42,\n                                      )","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:38.044899Z","iopub.execute_input":"2024-10-23T15:31:38.045178Z","iopub.status.idle":"2024-10-23T15:31:39.349021Z","shell.execute_reply.started":"2024-10-23T15:31:38.045154Z","shell.execute_reply":"2024-10-23T15:31:39.348100Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_train_datasets","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:39.350174Z","iopub.execute_input":"2024-10-23T15:31:39.350505Z","iopub.status.idle":"2024-10-23T15:31:39.356725Z","shell.execute_reply.started":"2024-10-23T15:31:39.350479Z","shell.execute_reply":"2024-10-23T15:31:39.355759Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'image_id', 'input_ids', 'attention_mask'],\n    num_rows: 9724\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_val_datasets","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:39.358064Z","iopub.execute_input":"2024-10-23T15:31:39.358928Z","iopub.status.idle":"2024-10-23T15:31:39.366580Z","shell.execute_reply.started":"2024-10-23T15:31:39.358902Z","shell.execute_reply":"2024-10-23T15:31:39.365806Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'image_id', 'input_ids', 'attention_mask'],\n    num_rows: 1081\n})"},"metadata":{}}]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model = model,\n    args = training_args,\n    train_dataset=tokenized_train_datasets,\n    eval_dataset=tokenized_val_datasets,\n    data_collator=data_collator,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:31:39.367712Z","iopub.execute_input":"2024-10-23T15:31:39.368015Z","iopub.status.idle":"2024-10-23T15:47:23.594628Z","shell.execute_reply.started":"2024-10-23T15:31:39.367991Z","shell.execute_reply":"2024-10-23T15:47:23.593718Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1216' max='1216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1216/1216 15:36, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>5.465300</td>\n      <td>0.126961</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.130900</td>\n      <td>0.120529</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.128000</td>\n      <td>0.110442</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.128500</td>\n      <td>0.126763</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.118600</td>\n      <td>0.115989</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.113300</td>\n      <td>0.109417</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.110100</td>\n      <td>0.107263</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.122100</td>\n      <td>0.110142</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.112800</td>\n      <td>0.105282</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.112100</td>\n      <td>0.107546</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.101400</td>\n      <td>0.107381</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.101200</td>\n      <td>0.108263</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1216, training_loss=0.5561858141108563, metrics={'train_runtime': 937.944, 'train_samples_per_second': 10.367, 'train_steps_per_second': 1.296, 'total_flos': 4630477128929280.0, 'train_loss': 0.5561858141108563, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport json\n\n# save loss\nlog_history = {'log_history':trainer.state.log_history}\n\nwith open('logs.json', 'w', encoding='utf-8') as f:\n    json.dump(log_history, f, ensure_ascii=False, indent=4)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:47:23.595877Z","iopub.execute_input":"2024-10-23T15:47:23.596176Z","iopub.status.idle":"2024-10-23T15:47:23.608502Z","shell.execute_reply.started":"2024-10-23T15:47:23.596151Z","shell.execute_reply":"2024-10-23T15:47:23.607526Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot\n\ntrain_loss = {i['step']:i['loss'] for i in log_history['log_history'] if 'loss' in i.keys()}\neval_loss = {i['step']:i['eval_loss'] for i in log_history['log_history'] if 'eval_loss' in i.keys()}\nplt.plot(list(train_loss.values()))\nplt.plot(list(eval_loss.values()))\n\nplt.yscale('log')\nplt.legend(['train','val'])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:47:23.609592Z","iopub.execute_input":"2024-10-23T15:47:23.609892Z","iopub.status.idle":"2024-10-23T15:47:25.013633Z","shell.execute_reply.started":"2024-10-23T15:47:23.609867Z","shell.execute_reply":"2024-10-23T15:47:25.012599Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x7b6a4893d990>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# Load checkpoints and predict","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()\n# model = T5ForConditionalGeneration.from_pretrained(\"/kaggle/working/checkpoint/checkpoint-500\")\n# model.to('cuda')\n# model.add_imgw(img_w)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:47:25.014974Z","iopub.execute_input":"2024-10-23T15:47:25.015273Z","iopub.status.idle":"2024-10-23T15:47:25.187962Z","shell.execute_reply.started":"2024-10-23T15:47:25.015247Z","shell.execute_reply":"2024-10-23T15:47:25.186827Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"\ndict_obj = {}\ndict_obj['inputs'] = test_df['caption']\ndict_obj['labels'] =  test_df['label']\ndict_obj['image_id'] = test_df['image_id']\ntest_dataset = Dataset.from_dict(dict_obj)\ntokenized_test_datasets = test_dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:47:25.189732Z","iopub.execute_input":"2024-10-23T15:47:25.190133Z","iopub.status.idle":"2024-10-23T15:47:27.429846Z","shell.execute_reply.started":"2024-10-23T15:47:25.190094Z","shell.execute_reply":"2024-10-23T15:47:27.428680Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"           ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd82ab92878644109d39d2a0c975ff08"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f71b5661684d4913b09c20345b0f971a"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3d86378d3f54981bf8c120dbcde3780"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e3bbe9e530c4a7fb0003bc48d755466"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3de76cef1a1c449ea35d41bd0d6c5ab5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db84d713b7684018b098775efa312d3d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a0d5a799db84b91847250d327b35ef4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d99ada702614cd78153e871baa0542e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:47:27.431587Z","iopub.execute_input":"2024-10-23T15:47:27.432626Z","iopub.status.idle":"2024-10-23T15:47:27.804659Z","shell.execute_reply.started":"2024-10-23T15:47:27.432584Z","shell.execute_reply":"2024-10-23T15:47:27.803657Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"2844"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_test_datasets","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:47:27.805942Z","iopub.execute_input":"2024-10-23T15:47:27.806235Z","iopub.status.idle":"2024-10-23T15:47:27.818365Z","shell.execute_reply.started":"2024-10-23T15:47:27.806209Z","shell.execute_reply":"2024-10-23T15:47:27.817523Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'image_id', 'input_ids', 'attention_mask'],\n    num_rows: 1413\n})"},"metadata":{}}]},{"cell_type":"code","source":"#test executing time: 2888s ~ 48m\nimport torch \nimport numpy as np\nfrom datasets import load_metric\nmetrics = load_metric('accuracy')\n\ntorch.cuda.empty_cache()\nmax_target_length = 10\ndataloader = torch.utils.data.DataLoader(tokenized_test_datasets, collate_fn=data_collator, batch_size=4) #replace tokenized_dev_datasets with tokenized_test_datasets\n\npredictions = []\nreferences = []\n\nfor i, batch in enumerate(tqdm(dataloader)):\n    # greedy search\n    outputs = model.generate(image_id = batch['image_id'],\n        input_ids=batch['input_ids'].to('cuda'),\n        max_length=max_target_length,\n        attention_mask=batch['attention_mask'].to('cuda'),\n        return_dict_in_generate=True, output_attentions=True,)\n\n    #beam search for now   \n    # outputs = model.generate(\n    #     image_id = np.repeat(batch['image_id'], 7),\n    #     input_ids=batch['input_ids'].to('cuda'),\n    #     max_length=max_target_length,\n    #     attention_mask=batch['attention_mask'].to('cuda'),\n    #     return_dict_in_generate=True, output_attentions=True,\n    #     num_beams=7,\n    #     no_repeat_ngram_size=2)\n    \n    with tokenizer.as_target_tokenizer():\n        outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs.sequences]\n        labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n        # actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n\n    predictions.extend(outputs)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:47:27.822068Z","iopub.execute_input":"2024-10-23T15:47:27.822650Z","iopub.status.idle":"2024-10-23T15:49:01.769682Z","shell.execute_reply.started":"2024-10-23T15:47:27.822618Z","shell.execute_reply":"2024-10-23T15:49:01.768738Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afb6fe573f87458eac8c98a96d5f2276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/354 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7ea75f237204da1be6516ae4e6e0c14"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"len(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:49:01.771134Z","iopub.execute_input":"2024-10-23T15:49:01.771438Z","iopub.status.idle":"2024-10-23T15:49:01.777754Z","shell.execute_reply.started":"2024-10-23T15:49:01.771411Z","shell.execute_reply":"2024-10-23T15:49:01.776693Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"1413"},"metadata":{}}]},{"cell_type":"code","source":"def postprocessing(t):\n    t = t.lower()\n    t = t.replace('\\\\','')\n    return t\n\ntest_predicted = {k:postprocessing(i) for k,i in zip(dev_json.keys(),predictions)}","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:49:01.779070Z","iopub.execute_input":"2024-10-23T15:49:01.779370Z","iopub.status.idle":"2024-10-23T15:49:01.789500Z","shell.execute_reply.started":"2024-10-23T15:49:01.779344Z","shell.execute_reply":"2024-10-23T15:49:01.788578Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"test_predicted","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:49:01.790733Z","iopub.execute_input":"2024-10-23T15:49:01.791071Z","iopub.status.idle":"2024-10-23T15:49:01.835557Z","shell.execute_reply.started":"2024-10-23T15:49:01.791036Z","shell.execute_reply":"2024-10-23T15:49:01.834559Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'0': 'multi-sarcasm',\n '1': 'multi-sarcasm',\n '2': 'not-sarcasm',\n '3': 'multi-sarcasm',\n '4': 'not-sarcasm',\n '5': 'not-sarcasm',\n '6': 'not-sarcasm',\n '7': 'not-sarcasm',\n '8': 'not-sarcasm',\n '9': 'not-sarcasm',\n '10': 'multi-sarcasm',\n '11': 'multi-sarcasm',\n '12': 'multi-sarcasm',\n '13': 'not-sarcasm',\n '14': 'multi-sarcasm',\n '15': 'not-sarcasm',\n '16': 'not-sarcasm',\n '17': 'not-sarcasm',\n '18': 'not-sarcasm',\n '19': 'not-sarcasm',\n '20': 'not-sarcasm',\n '21': 'not-sarcasm',\n '22': 'not-sarcasm',\n '23': 'not-sarcasm',\n '24': 'multi-sarcasm',\n '25': 'multi-sarcasm',\n '26': 'not-sarcasm',\n '27': 'not-sarcasm',\n '28': 'not-sarcasm',\n '29': 'not-sarcasm',\n '30': 'multi-sarcasm',\n '31': 'not-sarcasm',\n '32': 'not-sarcasm',\n '33': 'not-sarcasm',\n '34': 'not-sarcasm',\n '35': 'multi-sarcasm',\n '36': 'not-sarcasm',\n '37': 'multi-sarcasm',\n '38': 'not-sarcasm',\n '39': 'not-sarcasm',\n '40': 'multi-sarcasm',\n '41': 'not-sarcasm',\n '42': 'not-sarcasm',\n '43': 'not-sarcasm',\n '44': 'not-sarcasm',\n '45': 'not-sarcasm',\n '46': 'multi-sarcasm',\n '47': 'multi-sarcasm',\n '48': 'multi-sarcasm',\n '49': 'multi-sarcasm',\n '50': 'not-sarcasm',\n '51': 'multi-sarcasm',\n '52': 'multi-sarcasm',\n '53': 'multi-sarcasm',\n '54': 'multi-sarcasm',\n '55': 'not-sarcasm',\n '56': 'not-sarcasm',\n '57': 'not-sarcasm',\n '58': 'not-sarcasm',\n '59': 'not-sarcasm',\n '60': 'not-sarcasm',\n '61': 'not-sarcasm',\n '62': 'not-sarcasm',\n '63': 'not-sarcasm',\n '64': 'not-sarcasm',\n '65': 'multi-sarcasm',\n '66': 'not-sarcasm',\n '67': 'multi-sarcasm',\n '68': 'multi-sarcasm',\n '69': 'multi-sarcasm',\n '70': 'multi-sarcasm',\n '71': 'not-sarcasm',\n '72': 'multi-sarcasm',\n '73': 'not-sarcasm',\n '74': 'not-sarcasm',\n '75': 'multi-sarcasm',\n '76': 'not-sarcasm',\n '77': 'not-sarcasm',\n '78': 'not-sarcasm',\n '79': 'not-sarcasm',\n '80': 'multi-sarcasm',\n '81': 'not-sarcasm',\n '82': 'multi-sarcasm',\n '83': 'multi-sarcasm',\n '84': 'not-sarcasm',\n '85': 'not-sarcasm',\n '86': 'not-sarcasm',\n '87': 'not-sarcasm',\n '88': 'not-sarcasm',\n '89': 'not-sarcasm',\n '90': 'not-sarcasm',\n '91': 'not-sarcasm',\n '92': 'not-sarcasm',\n '93': 'multi-sarcasm',\n '94': 'multi-sarcasm',\n '95': 'multi-sarcasm',\n '96': 'not-sarcasm',\n '97': 'multi-sarcasm',\n '98': 'multi-sarcasm',\n '99': 'not-sarcasm',\n '100': 'not-sarcasm',\n '101': 'not-sarcasm',\n '102': 'not-sarcasm',\n '103': 'multi-sarcasm',\n '104': 'not-sarcasm',\n '105': 'not-sarcasm',\n '106': 'not-sarcasm',\n '107': 'not-sarcasm',\n '108': 'not-sarcasm',\n '109': 'multi-sarcasm',\n '110': 'multi-sarcasm',\n '111': 'not-sarcasm',\n '112': 'multi-sarcasm',\n '113': 'not-sarcasm',\n '114': 'not-sarcasm',\n '115': 'multi-sarcasm',\n '116': 'multi-sarcasm',\n '117': 'not-sarcasm',\n '118': 'multi-sarcasm',\n '119': 'multi-sarcasm',\n '120': 'not-sarcasm',\n '121': 'not-sarcasm',\n '122': 'not-sarcasm',\n '123': 'not-sarcasm',\n '124': 'not-sarcasm',\n '125': 'not-sarcasm',\n '126': 'not-sarcasm',\n '127': 'not-sarcasm',\n '128': 'not-sarcasm',\n '129': 'not-sarcasm',\n '130': 'not-sarcasm',\n '131': 'not-sarcasm',\n '132': 'not-sarcasm',\n '133': 'not-sarcasm',\n '134': 'not-sarcasm',\n '135': 'not-sarcasm',\n '136': 'not-sarcasm',\n '137': 'not-sarcasm',\n '138': 'not-sarcasm',\n '139': 'not-sarcasm',\n '140': 'not-sarcasm',\n '141': 'not-sarcasm',\n '142': 'not-sarcasm',\n '143': 'not-sarcasm',\n '144': 'not-sarcasm',\n '145': 'not-sarcasm',\n '146': 'not-sarcasm',\n '147': 'not-sarcasm',\n '148': 'not-sarcasm',\n '149': 'not-sarcasm',\n '150': 'not-sarcasm',\n '151': 'multi-sarcasm',\n '152': 'multi-sarcasm',\n '153': 'not-sarcasm',\n '154': 'multi-sarcasm',\n '155': 'not-sarcasm',\n '156': 'multi-sarcasm',\n '157': 'not-sarcasm',\n '158': 'multi-sarcasm',\n '159': 'not-sarcasm',\n '160': 'multi-sarcasm',\n '161': 'multi-sarcasm',\n '162': 'not-sarcasm',\n '163': 'not-sarcasm',\n '164': 'not-sarcasm',\n '165': 'multi-sarcasm',\n '166': 'multi-sarcasm',\n '167': 'multi-sarcasm',\n '168': 'multi-sarcasm',\n '169': 'multi-sarcasm',\n '170': 'not-sarcasm',\n '171': 'multi-sarcasm',\n '172': 'not-sarcasm',\n '173': 'not-sarcasm',\n '174': 'not-sarcasm',\n '175': 'not-sarcasm',\n '176': 'not-sarcasm',\n '177': 'not-sarcasm',\n '178': 'not-sarcasm',\n '179': 'multi-sarcasm',\n '180': 'multi-sarcasm',\n '181': 'not-sarcasm',\n '182': 'not-sarcasm',\n '183': 'not-sarcasm',\n '184': 'not-sarcasm',\n '185': 'not-sarcasm',\n '186': 'multi-sarcasm',\n '187': 'not-sarcasm',\n '188': 'not-sarcasm',\n '189': 'not-sarcasm',\n '190': 'not-sarcasm',\n '191': 'not-sarcasm',\n '192': 'multi-sarcasm',\n '193': 'multi-sarcasm',\n '194': 'multi-sarcasm',\n '195': 'multi-sarcasm',\n '196': 'not-sarcasm',\n '197': 'not-sarcasm',\n '198': 'not-sarcasm',\n '199': 'not-sarcasm',\n '200': 'not-sarcasm',\n '201': 'not-sarcasm',\n '202': 'not-sarcasm',\n '203': 'not-sarcasm',\n '204': 'not-sarcasm',\n '205': 'multi-sarcasm',\n '206': 'multi-sarcasm',\n '207': 'not-sarcasm',\n '208': 'not-sarcasm',\n '209': 'not-sarcasm',\n '210': 'not-sarcasm',\n '211': 'not-sarcasm',\n '212': 'multi-sarcasm',\n '213': 'not-sarcasm',\n '214': 'not-sarcasm',\n '215': 'multi-sarcasm',\n '216': 'not-sarcasm',\n '217': 'not-sarcasm',\n '218': 'not-sarcasm',\n '219': 'multi-sarcasm',\n '220': 'multi-sarcasm',\n '221': 'not-sarcasm',\n '222': 'not-sarcasm',\n '223': 'multi-sarcasm',\n '224': 'not-sarcasm',\n '225': 'not-sarcasm',\n '226': 'multi-sarcasm',\n '227': 'not-sarcasm',\n '228': 'not-sarcasm',\n '229': 'multi-sarcasm',\n '230': 'multi-sarcasm',\n '231': 'multi-sarcasm',\n '232': 'multi-sarcasm',\n '233': 'multi-sarcasm',\n '234': 'not-sarcasm',\n '235': 'not-sarcasm',\n '236': 'not-sarcasm',\n '237': 'not-sarcasm',\n '238': 'not-sarcasm',\n '239': 'not-sarcasm',\n '240': 'not-sarcasm',\n '241': 'not-sarcasm',\n '242': 'not-sarcasm',\n '243': 'not-sarcasm',\n '244': 'not-sarcasm',\n '245': 'not-sarcasm',\n '246': 'not-sarcasm',\n '247': 'multi-sarcasm',\n '248': 'multi-sarcasm',\n '249': 'not-sarcasm',\n '250': 'not-sarcasm',\n '251': 'not-sarcasm',\n '252': 'not-sarcasm',\n '253': 'multi-sarcasm',\n '254': 'not-sarcasm',\n '255': 'not-sarcasm',\n '256': 'not-sarcasm',\n '257': 'not-sarcasm',\n '258': 'not-sarcasm',\n '259': 'not-sarcasm',\n '260': 'multi-sarcasm',\n '261': 'not-sarcasm',\n '262': 'multi-sarcasm',\n '263': 'multi-sarcasm',\n '264': 'not-sarcasm',\n '265': 'not-sarcasm',\n '266': 'multi-sarcasm',\n '267': 'multi-sarcasm',\n '268': 'multi-sarcasm',\n '269': 'multi-sarcasm',\n '270': 'multi-sarcasm',\n '271': 'multi-sarcasm',\n '272': 'multi-sarcasm',\n '273': 'multi-sarcasm',\n '274': 'not-sarcasm',\n '275': 'multi-sarcasm',\n '276': 'not-sarcasm',\n '277': 'not-sarcasm',\n '278': 'multi-sarcasm',\n '279': 'multi-sarcasm',\n '280': 'not-sarcasm',\n '281': 'not-sarcasm',\n '282': 'not-sarcasm',\n '283': 'not-sarcasm',\n '284': 'not-sarcasm',\n '285': 'multi-sarcasm',\n '286': 'multi-sarcasm',\n '287': 'not-sarcasm',\n '288': 'multi-sarcasm',\n '289': 'multi-sarcasm',\n '290': 'multi-sarcasm',\n '291': 'multi-sarcasm',\n '292': 'not-sarcasm',\n '293': 'not-sarcasm',\n '294': 'not-sarcasm',\n '295': 'multi-sarcasm',\n '296': 'not-sarcasm',\n '297': 'multi-sarcasm',\n '298': 'multi-sarcasm',\n '299': 'multi-sarcasm',\n '300': 'not-sarcasm',\n '301': 'not-sarcasm',\n '302': 'not-sarcasm',\n '303': 'not-sarcasm',\n '304': 'not-sarcasm',\n '305': 'not-sarcasm',\n '306': 'multi-sarcasm',\n '307': 'multi-sarcasm',\n '308': 'not-sarcasm',\n '309': 'multi-sarcasm',\n '310': 'not-sarcasm',\n '311': 'not-sarcasm',\n '312': 'multi-sarcasm',\n '313': 'not-sarcasm',\n '314': 'not-sarcasm',\n '315': 'not-sarcasm',\n '316': 'not-sarcasm',\n '317': 'not-sarcasm',\n '318': 'not-sarcasm',\n '319': 'not-sarcasm',\n '320': 'multi-sarcasm',\n '321': 'multi-sarcasm',\n '322': 'multi-sarcasm',\n '323': 'multi-sarcasm',\n '324': 'multi-sarcasm',\n '325': 'not-sarcasm',\n '326': 'multi-sarcasm',\n '327': 'multi-sarcasm',\n '328': 'not-sarcasm',\n '329': 'not-sarcasm',\n '330': 'not-sarcasm',\n '331': 'not-sarcasm',\n '332': 'not-sarcasm',\n '333': 'not-sarcasm',\n '334': 'multi-sarcasm',\n '335': 'not-sarcasm',\n '336': 'not-sarcasm',\n '337': 'not-sarcasm',\n '338': 'multi-sarcasm',\n '339': 'multi-sarcasm',\n '340': 'not-sarcasm',\n '341': 'not-sarcasm',\n '342': 'not-sarcasm',\n '343': 'multi-sarcasm',\n '344': 'not-sarcasm',\n '345': 'not-sarcasm',\n '346': 'not-sarcasm',\n '347': 'not-sarcasm',\n '348': 'not-sarcasm',\n '349': 'not-sarcasm',\n '350': 'not-sarcasm',\n '351': 'not-sarcasm',\n '352': 'not-sarcasm',\n '353': 'not-sarcasm',\n '354': 'not-sarcasm',\n '355': 'not-sarcasm',\n '356': 'not-sarcasm',\n '357': 'not-sarcasm',\n '358': 'not-sarcasm',\n '359': 'not-sarcasm',\n '360': 'not-sarcasm',\n '361': 'not-sarcasm',\n '362': 'not-sarcasm',\n '363': 'not-sarcasm',\n '364': 'not-sarcasm',\n '365': 'not-sarcasm',\n '366': 'not-sarcasm',\n '367': 'not-sarcasm',\n '368': 'not-sarcasm',\n '369': 'not-sarcasm',\n '370': 'not-sarcasm',\n '371': 'not-sarcasm',\n '372': 'not-sarcasm',\n '373': 'not-sarcasm',\n '374': 'not-sarcasm',\n '375': 'not-sarcasm',\n '376': 'not-sarcasm',\n '377': 'not-sarcasm',\n '378': 'not-sarcasm',\n '379': 'not-sarcasm',\n '380': 'not-sarcasm',\n '381': 'not-sarcasm',\n '382': 'not-sarcasm',\n '383': 'not-sarcasm',\n '384': 'not-sarcasm',\n '385': 'not-sarcasm',\n '386': 'not-sarcasm',\n '387': 'not-sarcasm',\n '388': 'not-sarcasm',\n '389': 'not-sarcasm',\n '390': 'not-sarcasm',\n '391': 'not-sarcasm',\n '392': 'multi-sarcasm',\n '393': 'not-sarcasm',\n '394': 'multi-sarcasm',\n '395': 'not-sarcasm',\n '396': 'not-sarcasm',\n '397': 'not-sarcasm',\n '398': 'not-sarcasm',\n '399': 'multi-sarcasm',\n '400': 'not-sarcasm',\n '401': 'not-sarcasm',\n '402': 'not-sarcasm',\n '403': 'not-sarcasm',\n '404': 'not-sarcasm',\n '405': 'multi-sarcasm',\n '406': 'not-sarcasm',\n '407': 'not-sarcasm',\n '408': 'not-sarcasm',\n '409': 'not-sarcasm',\n '410': 'not-sarcasm',\n '411': 'multi-sarcasm',\n '412': 'multi-sarcasm',\n '413': 'not-sarcasm',\n '414': 'not-sarcasm',\n '415': 'multi-sarcasm',\n '416': 'not-sarcasm',\n '417': 'not-sarcasm',\n '418': 'multi-sarcasm',\n '419': 'multi-sarcasm',\n '420': 'multi-sarcasm',\n '421': 'not-sarcasm',\n '422': 'not-sarcasm',\n '423': 'not-sarcasm',\n '424': 'not-sarcasm',\n '425': 'not-sarcasm',\n '426': 'not-sarcasm',\n '427': 'not-sarcasm',\n '428': 'not-sarcasm',\n '429': 'not-sarcasm',\n '430': 'not-sarcasm',\n '431': 'multi-sarcasm',\n '432': 'not-sarcasm',\n '433': 'not-sarcasm',\n '434': 'not-sarcasm',\n '435': 'not-sarcasm',\n '436': 'not-sarcasm',\n '437': 'not-sarcasm',\n '438': 'not-sarcasm',\n '439': 'multi-sarcasm',\n '440': 'not-sarcasm',\n '441': 'not-sarcasm',\n '442': 'not-sarcasm',\n '443': 'multi-sarcasm',\n '444': 'multi-sarcasm',\n '445': 'not-sarcasm',\n '446': 'multi-sarcasm',\n '447': 'not-sarcasm',\n '448': 'not-sarcasm',\n '449': 'multi-sarcasm',\n '450': 'not-sarcasm',\n '451': 'not-sarcasm',\n '452': 'not-sarcasm',\n '453': 'not-sarcasm',\n '454': 'not-sarcasm',\n '455': 'not-sarcasm',\n '456': 'not-sarcasm',\n '457': 'not-sarcasm',\n '458': 'not-sarcasm',\n '459': 'not-sarcasm',\n '460': 'not-sarcasm',\n '461': 'not-sarcasm',\n '462': 'not-sarcasm',\n '463': 'not-sarcasm',\n '464': 'not-sarcasm',\n '465': 'multi-sarcasm',\n '466': 'not-sarcasm',\n '467': 'not-sarcasm',\n '468': 'not-sarcasm',\n '469': 'not-sarcasm',\n '470': 'not-sarcasm',\n '471': 'not-sarcasm',\n '472': 'not-sarcasm',\n '473': 'not-sarcasm',\n '474': 'not-sarcasm',\n '475': 'not-sarcasm',\n '476': 'not-sarcasm',\n '477': 'not-sarcasm',\n '478': 'not-sarcasm',\n '479': 'not-sarcasm',\n '480': 'multi-sarcasm',\n '481': 'not-sarcasm',\n '482': 'multi-sarcasm',\n '483': 'not-sarcasm',\n '484': 'multi-sarcasm',\n '485': 'multi-sarcasm',\n '486': 'multi-sarcasm',\n '487': 'not-sarcasm',\n '488': 'multi-sarcasm',\n '489': 'not-sarcasm',\n '490': 'not-sarcasm',\n '491': 'not-sarcasm',\n '492': 'multi-sarcasm',\n '493': 'multi-sarcasm',\n '494': 'multi-sarcasm',\n '495': 'multi-sarcasm',\n '496': 'not-sarcasm',\n '497': 'multi-sarcasm',\n '498': 'not-sarcasm',\n '499': 'not-sarcasm',\n '500': 'not-sarcasm',\n '501': 'multi-sarcasm',\n '502': 'not-sarcasm',\n '503': 'not-sarcasm',\n '504': 'not-sarcasm',\n '505': 'multi-sarcasm',\n '506': 'not-sarcasm',\n '507': 'not-sarcasm',\n '508': 'not-sarcasm',\n '509': 'not-sarcasm',\n '510': 'multi-sarcasm',\n '511': 'not-sarcasm',\n '512': 'multi-sarcasm',\n '513': 'multi-sarcasm',\n '514': 'not-sarcasm',\n '515': 'multi-sarcasm',\n '516': 'not-sarcasm',\n '517': 'not-sarcasm',\n '518': 'not-sarcasm',\n '519': 'not-sarcasm',\n '520': 'multi-sarcasm',\n '521': 'multi-sarcasm',\n '522': 'not-sarcasm',\n '523': 'not-sarcasm',\n '524': 'multi-sarcasm',\n '525': 'multi-sarcasm',\n '526': 'not-sarcasm',\n '527': 'not-sarcasm',\n '528': 'not-sarcasm',\n '529': 'not-sarcasm',\n '530': 'multi-sarcasm',\n '531': 'multi-sarcasm',\n '532': 'multi-sarcasm',\n '533': 'multi-sarcasm',\n '534': 'not-sarcasm',\n '535': 'multi-sarcasm',\n '536': 'multi-sarcasm',\n '537': 'multi-sarcasm',\n '538': 'multi-sarcasm',\n '539': 'not-sarcasm',\n '540': 'not-sarcasm',\n '541': 'multi-sarcasm',\n '542': 'not-sarcasm',\n '543': 'not-sarcasm',\n '544': 'multi-sarcasm',\n '545': 'multi-sarcasm',\n '546': 'not-sarcasm',\n '547': 'multi-sarcasm',\n '548': 'not-sarcasm',\n '549': 'multi-sarcasm',\n '550': 'multi-sarcasm',\n '551': 'multi-sarcasm',\n '552': 'multi-sarcasm',\n '553': 'multi-sarcasm',\n '554': 'multi-sarcasm',\n '555': 'multi-sarcasm',\n '556': 'multi-sarcasm',\n '557': 'multi-sarcasm',\n '558': 'not-sarcasm',\n '559': 'multi-sarcasm',\n '560': 'multi-sarcasm',\n '561': 'not-sarcasm',\n '562': 'multi-sarcasm',\n '563': 'not-sarcasm',\n '564': 'not-sarcasm',\n '565': 'not-sarcasm',\n '566': 'multi-sarcasm',\n '567': 'multi-sarcasm',\n '568': 'multi-sarcasm',\n '569': 'multi-sarcasm',\n '570': 'not-sarcasm',\n '571': 'not-sarcasm',\n '572': 'not-sarcasm',\n '573': 'not-sarcasm',\n '574': 'multi-sarcasm',\n '575': 'multi-sarcasm',\n '576': 'multi-sarcasm',\n '577': 'multi-sarcasm',\n '578': 'multi-sarcasm',\n '579': 'not-sarcasm',\n '580': 'multi-sarcasm',\n '581': 'multi-sarcasm',\n '582': 'multi-sarcasm',\n '583': 'multi-sarcasm',\n '584': 'not-sarcasm',\n '585': 'multi-sarcasm',\n '586': 'multi-sarcasm',\n '587': 'multi-sarcasm',\n '588': 'not-sarcasm',\n '589': 'not-sarcasm',\n '590': 'multi-sarcasm',\n '591': 'multi-sarcasm',\n '592': 'not-sarcasm',\n '593': 'not-sarcasm',\n '594': 'multi-sarcasm',\n '595': 'not-sarcasm',\n '596': 'multi-sarcasm',\n '597': 'not-sarcasm',\n '598': 'not-sarcasm',\n '599': 'multi-sarcasm',\n '600': 'multi-sarcasm',\n '601': 'not-sarcasm',\n '602': 'not-sarcasm',\n '603': 'multi-sarcasm',\n '604': 'not-sarcasm',\n '605': 'not-sarcasm',\n '606': 'multi-sarcasm',\n '607': 'multi-sarcasm',\n '608': 'not-sarcasm',\n '609': 'multi-sarcasm',\n '610': 'multi-sarcasm',\n '611': 'multi-sarcasm',\n '612': 'multi-sarcasm',\n '613': 'not-sarcasm',\n '614': 'multi-sarcasm',\n '615': 'not-sarcasm',\n '616': 'multi-sarcasm',\n '617': 'multi-sarcasm',\n '618': 'multi-sarcasm',\n '619': 'multi-sarcasm',\n '620': 'multi-sarcasm',\n '621': 'not-sarcasm',\n '622': 'multi-sarcasm',\n '623': 'multi-sarcasm',\n '624': 'not-sarcasm',\n '625': 'not-sarcasm',\n '626': 'multi-sarcasm',\n '627': 'multi-sarcasm',\n '628': 'not-sarcasm',\n '629': 'not-sarcasm',\n '630': 'multi-sarcasm',\n '631': 'multi-sarcasm',\n '632': 'multi-sarcasm',\n '633': 'not-sarcasm',\n '634': 'multi-sarcasm',\n '635': 'not-sarcasm',\n '636': 'multi-sarcasm',\n '637': 'not-sarcasm',\n '638': 'multi-sarcasm',\n '639': 'not-sarcasm',\n '640': 'not-sarcasm',\n '641': 'not-sarcasm',\n '642': 'multi-sarcasm',\n '643': 'multi-sarcasm',\n '644': 'multi-sarcasm',\n '645': 'not-sarcasm',\n '646': 'not-sarcasm',\n '647': 'multi-sarcasm',\n '648': 'multi-sarcasm',\n '649': 'multi-sarcasm',\n '650': 'multi-sarcasm',\n '651': 'not-sarcasm',\n '652': 'multi-sarcasm',\n '653': 'multi-sarcasm',\n '654': 'not-sarcasm',\n '655': 'not-sarcasm',\n '656': 'not-sarcasm',\n '657': 'not-sarcasm',\n '658': 'not-sarcasm',\n '659': 'multi-sarcasm',\n '660': 'multi-sarcasm',\n '661': 'multi-sarcasm',\n '662': 'multi-sarcasm',\n '663': 'multi-sarcasm',\n '664': 'not-sarcasm',\n '665': 'multi-sarcasm',\n '666': 'not-sarcasm',\n '667': 'not-sarcasm',\n '668': 'multi-sarcasm',\n '669': 'not-sarcasm',\n '670': 'not-sarcasm',\n '671': 'not-sarcasm',\n '672': 'not-sarcasm',\n '673': 'not-sarcasm',\n '674': 'not-sarcasm',\n '675': 'not-sarcasm',\n '676': 'multi-sarcasm',\n '677': 'not-sarcasm',\n '678': 'multi-sarcasm',\n '679': 'multi-sarcasm',\n '680': 'multi-sarcasm',\n '681': 'multi-sarcasm',\n '682': 'not-sarcasm',\n '683': 'multi-sarcasm',\n '684': 'multi-sarcasm',\n '685': 'not-sarcasm',\n '686': 'multi-sarcasm',\n '687': 'not-sarcasm',\n '688': 'not-sarcasm',\n '689': 'not-sarcasm',\n '690': 'not-sarcasm',\n '691': 'multi-sarcasm',\n '692': 'not-sarcasm',\n '693': 'multi-sarcasm',\n '694': 'multi-sarcasm',\n '695': 'not-sarcasm',\n '696': 'not-sarcasm',\n '697': 'not-sarcasm',\n '698': 'not-sarcasm',\n '699': 'not-sarcasm',\n '700': 'not-sarcasm',\n '701': 'not-sarcasm',\n '702': 'multi-sarcasm',\n '703': 'not-sarcasm',\n '704': 'not-sarcasm',\n '705': 'multi-sarcasm',\n '706': 'multi-sarcasm',\n '707': 'multi-sarcasm',\n '708': 'not-sarcasm',\n '709': 'multi-sarcasm',\n '710': 'multi-sarcasm',\n '711': 'multi-sarcasm',\n '712': 'multi-sarcasm',\n '713': 'not-sarcasm',\n '714': 'not-sarcasm',\n '715': 'multi-sarcasm',\n '716': 'multi-sarcasm',\n '717': 'not-sarcasm',\n '718': 'multi-sarcasm',\n '719': 'not-sarcasm',\n '720': 'multi-sarcasm',\n '721': 'not-sarcasm',\n '722': 'not-sarcasm',\n '723': 'multi-sarcasm',\n '724': 'not-sarcasm',\n '725': 'not-sarcasm',\n '726': 'not-sarcasm',\n '727': 'multi-sarcasm',\n '728': 'not-sarcasm',\n '729': 'not-sarcasm',\n '730': 'multi-sarcasm',\n '731': 'not-sarcasm',\n '732': 'not-sarcasm',\n '733': 'multi-sarcasm',\n '734': 'multi-sarcasm',\n '735': 'multi-sarcasm',\n '736': 'not-sarcasm',\n '737': 'not-sarcasm',\n '738': 'not-sarcasm',\n '739': 'not-sarcasm',\n '740': 'not-sarcasm',\n '741': 'multi-sarcasm',\n '742': 'multi-sarcasm',\n '743': 'multi-sarcasm',\n '744': 'not-sarcasm',\n '745': 'not-sarcasm',\n '746': 'not-sarcasm',\n '747': 'not-sarcasm',\n '748': 'multi-sarcasm',\n '749': 'not-sarcasm',\n '750': 'not-sarcasm',\n '751': 'multi-sarcasm',\n '752': 'multi-sarcasm',\n '753': 'multi-sarcasm',\n '754': 'multi-sarcasm',\n '755': 'not-sarcasm',\n '756': 'not-sarcasm',\n '757': 'multi-sarcasm',\n '758': 'not-sarcasm',\n '759': 'not-sarcasm',\n '760': 'not-sarcasm',\n '761': 'not-sarcasm',\n '762': 'not-sarcasm',\n '763': 'multi-sarcasm',\n '764': 'not-sarcasm',\n '765': 'multi-sarcasm',\n '766': 'multi-sarcasm',\n '767': 'not-sarcasm',\n '768': 'multi-sarcasm',\n '769': 'multi-sarcasm',\n '770': 'multi-sarcasm',\n '771': 'multi-sarcasm',\n '772': 'not-sarcasm',\n '773': 'not-sarcasm',\n '774': 'multi-sarcasm',\n '775': 'multi-sarcasm',\n '776': 'multi-sarcasm',\n '777': 'not-sarcasm',\n '778': 'not-sarcasm',\n '779': 'not-sarcasm',\n '780': 'multi-sarcasm',\n '781': 'multi-sarcasm',\n '782': 'not-sarcasm',\n '783': 'not-sarcasm',\n '784': 'not-sarcasm',\n '785': 'not-sarcasm',\n '786': 'not-sarcasm',\n '787': 'multi-sarcasm',\n '788': 'not-sarcasm',\n '789': 'not-sarcasm',\n '790': 'not-sarcasm',\n '791': 'not-sarcasm',\n '792': 'not-sarcasm',\n '793': 'multi-sarcasm',\n '794': 'multi-sarcasm',\n '795': 'not-sarcasm',\n '796': 'not-sarcasm',\n '797': 'not-sarcasm',\n '798': 'not-sarcasm',\n '799': 'multi-sarcasm',\n '800': 'not-sarcasm',\n '801': 'multi-sarcasm',\n '802': 'multi-sarcasm',\n '803': 'not-sarcasm',\n '804': 'not-sarcasm',\n '805': 'multi-sarcasm',\n '806': 'multi-sarcasm',\n '807': 'not-sarcasm',\n '808': 'multi-sarcasm',\n '809': 'not-sarcasm',\n '810': 'multi-sarcasm',\n '811': 'not-sarcasm',\n '812': 'multi-sarcasm',\n '813': 'multi-sarcasm',\n '814': 'multi-sarcasm',\n '815': 'not-sarcasm',\n '816': 'not-sarcasm',\n '817': 'multi-sarcasm',\n '818': 'multi-sarcasm',\n '819': 'not-sarcasm',\n '820': 'multi-sarcasm',\n '821': 'multi-sarcasm',\n '822': 'multi-sarcasm',\n '823': 'not-sarcasm',\n '824': 'not-sarcasm',\n '825': 'not-sarcasm',\n '826': 'not-sarcasm',\n '827': 'not-sarcasm',\n '828': 'multi-sarcasm',\n '829': 'multi-sarcasm',\n '830': 'not-sarcasm',\n '831': 'not-sarcasm',\n '832': 'multi-sarcasm',\n '833': 'not-sarcasm',\n '834': 'not-sarcasm',\n '835': 'multi-sarcasm',\n '836': 'not-sarcasm',\n '837': 'not-sarcasm',\n '838': 'not-sarcasm',\n '839': 'multi-sarcasm',\n '840': 'not-sarcasm',\n '841': 'not-sarcasm',\n '842': 'multi-sarcasm',\n '843': 'multi-sarcasm',\n '844': 'multi-sarcasm',\n '845': 'multi-sarcasm',\n '846': 'not-sarcasm',\n '847': 'not-sarcasm',\n '848': 'multi-sarcasm',\n '849': 'multi-sarcasm',\n '850': 'multi-sarcasm',\n '851': 'not-sarcasm',\n '852': 'multi-sarcasm',\n '853': 'not-sarcasm',\n '854': 'multi-sarcasm',\n '855': 'not-sarcasm',\n '856': 'not-sarcasm',\n '857': 'multi-sarcasm',\n '858': 'multi-sarcasm',\n '859': 'multi-sarcasm',\n '860': 'not-sarcasm',\n '861': 'multi-sarcasm',\n '862': 'multi-sarcasm',\n '863': 'multi-sarcasm',\n '864': 'multi-sarcasm',\n '865': 'multi-sarcasm',\n '866': 'multi-sarcasm',\n '867': 'not-sarcasm',\n '868': 'not-sarcasm',\n '869': 'not-sarcasm',\n '870': 'multi-sarcasm',\n '871': 'not-sarcasm',\n '872': 'not-sarcasm',\n '873': 'not-sarcasm',\n '874': 'multi-sarcasm',\n '875': 'multi-sarcasm',\n '876': 'not-sarcasm',\n '877': 'not-sarcasm',\n '878': 'multi-sarcasm',\n '879': 'not-sarcasm',\n '880': 'not-sarcasm',\n '881': 'multi-sarcasm',\n '882': 'multi-sarcasm',\n '883': 'not-sarcasm',\n '884': 'multi-sarcasm',\n '885': 'not-sarcasm',\n '886': 'multi-sarcasm',\n '887': 'not-sarcasm',\n '888': 'multi-sarcasm',\n '889': 'multi-sarcasm',\n '890': 'multi-sarcasm',\n '891': 'multi-sarcasm',\n '892': 'not-sarcasm',\n '893': 'multi-sarcasm',\n '894': 'multi-sarcasm',\n '895': 'multi-sarcasm',\n '896': 'multi-sarcasm',\n '897': 'not-sarcasm',\n '898': 'multi-sarcasm',\n '899': 'multi-sarcasm',\n '900': 'multi-sarcasm',\n '901': 'multi-sarcasm',\n '902': 'multi-sarcasm',\n '903': 'not-sarcasm',\n '904': 'multi-sarcasm',\n '905': 'multi-sarcasm',\n '906': 'not-sarcasm',\n '907': 'multi-sarcasm',\n '908': 'multi-sarcasm',\n '909': 'multi-sarcasm',\n '910': 'not-sarcasm',\n '911': 'multi-sarcasm',\n '912': 'multi-sarcasm',\n '913': 'multi-sarcasm',\n '914': 'not-sarcasm',\n '915': 'not-sarcasm',\n '916': 'multi-sarcasm',\n '917': 'not-sarcasm',\n '918': 'not-sarcasm',\n '919': 'multi-sarcasm',\n '920': 'not-sarcasm',\n '921': 'not-sarcasm',\n '922': 'multi-sarcasm',\n '923': 'multi-sarcasm',\n '924': 'multi-sarcasm',\n '925': 'multi-sarcasm',\n '926': 'not-sarcasm',\n '927': 'not-sarcasm',\n '928': 'not-sarcasm',\n '929': 'multi-sarcasm',\n '930': 'multi-sarcasm',\n '931': 'not-sarcasm',\n '932': 'not-sarcasm',\n '933': 'multi-sarcasm',\n '934': 'multi-sarcasm',\n '935': 'multi-sarcasm',\n '936': 'multi-sarcasm',\n '937': 'multi-sarcasm',\n '938': 'multi-sarcasm',\n '939': 'multi-sarcasm',\n '940': 'multi-sarcasm',\n '941': 'not-sarcasm',\n '942': 'not-sarcasm',\n '943': 'not-sarcasm',\n '944': 'not-sarcasm',\n '945': 'not-sarcasm',\n '946': 'multi-sarcasm',\n '947': 'multi-sarcasm',\n '948': 'multi-sarcasm',\n '949': 'not-sarcasm',\n '950': 'multi-sarcasm',\n '951': 'not-sarcasm',\n '952': 'not-sarcasm',\n '953': 'multi-sarcasm',\n '954': 'not-sarcasm',\n '955': 'not-sarcasm',\n '956': 'multi-sarcasm',\n '957': 'not-sarcasm',\n '958': 'multi-sarcasm',\n '959': 'not-sarcasm',\n '960': 'not-sarcasm',\n '961': 'not-sarcasm',\n '962': 'not-sarcasm',\n '963': 'not-sarcasm',\n '964': 'multi-sarcasm',\n '965': 'multi-sarcasm',\n '966': 'multi-sarcasm',\n '967': 'multi-sarcasm',\n '968': 'multi-sarcasm',\n '969': 'not-sarcasm',\n '970': 'not-sarcasm',\n '971': 'not-sarcasm',\n '972': 'not-sarcasm',\n '973': 'not-sarcasm',\n '974': 'multi-sarcasm',\n '975': 'not-sarcasm',\n '976': 'multi-sarcasm',\n '977': 'multi-sarcasm',\n '978': 'not-sarcasm',\n '979': 'multi-sarcasm',\n '980': 'multi-sarcasm',\n '981': 'multi-sarcasm',\n '982': 'not-sarcasm',\n '983': 'multi-sarcasm',\n '984': 'multi-sarcasm',\n '985': 'multi-sarcasm',\n '986': 'multi-sarcasm',\n '987': 'multi-sarcasm',\n '988': 'multi-sarcasm',\n '989': 'multi-sarcasm',\n '990': 'multi-sarcasm',\n '991': 'not-sarcasm',\n '992': 'multi-sarcasm',\n '993': 'multi-sarcasm',\n '994': 'multi-sarcasm',\n '995': 'multi-sarcasm',\n '996': 'not-sarcasm',\n '997': 'multi-sarcasm',\n '998': 'multi-sarcasm',\n '999': 'not-sarcasm',\n ...}"},"metadata":{}}]},{"cell_type":"code","source":"with open('results.json', 'w') as fp:\n    json.dump(test_predicted, fp,ensure_ascii=True,indent=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T15:49:01.836685Z","iopub.execute_input":"2024-10-23T15:49:01.836999Z","iopub.status.idle":"2024-10-23T15:49:01.847160Z","shell.execute_reply.started":"2024-10-23T15:49:01.836971Z","shell.execute_reply":"2024-10-23T15:49:01.846279Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}