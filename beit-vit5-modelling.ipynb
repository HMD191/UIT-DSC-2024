{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9571267,"sourceType":"datasetVersion","datasetId":5834049},{"sourceId":9660707,"sourceType":"datasetVersion","datasetId":5902254},{"sourceId":9774475,"sourceType":"datasetVersion","datasetId":5987472},{"sourceId":9793891,"sourceType":"datasetVersion","datasetId":5953272}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Import Libraries and Load Dataset","metadata":{}},{"cell_type":"code","source":"%%capture\n#!git clone https://github.com/huggingface/transformers.git\n!pip install datasets evaluate transformers[sentencepiece]\n!pip install pyvi\n!pip install gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:41:44.253193Z","iopub.execute_input":"2024-11-04T08:41:44.253609Z","iopub.status.idle":"2024-11-04T08:42:21.803353Z","shell.execute_reply.started":"2024-11-04T08:41:44.253576Z","shell.execute_reply":"2024-11-04T08:42:21.802326Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#%%capture\n\nimport gdown\n\n!gdown 1jWDnP1xF01_pmeJYsRHxSVBkLZ0I9LAt #utils T5 for VQA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:42:21.805348Z","iopub.execute_input":"2024-11-04T08:42:21.805650Z","iopub.status.idle":"2024-11-04T08:42:27.709789Z","shell.execute_reply.started":"2024-11-04T08:42:21.805625Z","shell.execute_reply":"2024-11-04T08:42:27.708818Z"}},"outputs":[{"name":"stdout","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1jWDnP1xF01_pmeJYsRHxSVBkLZ0I9LAt\nFrom (redirected): https://drive.google.com/uc?id=1jWDnP1xF01_pmeJYsRHxSVBkLZ0I9LAt&confirm=t&uuid=dfb0c7c9-edfd-481b-9a19-ce44f1665398\nTo: /kaggle/working/utils.py\n100%|████████████████████████████████████████| 109k/109k [00:00<00:00, 82.5MB/s]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from PIL import Image\n\nimport requests\n\nimport os\nimport shutil\nimport torch\n\nfrom urllib.request import urlopen\nfrom PIL import Image\nimport timm\nimport tqdm\nimport torch\nfrom IPython.display import FileLink","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:42:27.711157Z","iopub.execute_input":"2024-11-04T08:42:27.711838Z","iopub.status.idle":"2024-11-04T08:42:31.957843Z","shell.execute_reply.started":"2024-11-04T08:42:27.711810Z","shell.execute_reply":"2024-11-04T08:42:31.956110Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import json\n\ntrain_json = json.load(open('/kaggle/input/dsc24-vimmsd/vimmsd-train.json', encoding='utf-8'))\ndev_json = json.load(open('/kaggle/input/dsc24-vimmsd/vimmsd-public-test.json', encoding='utf-8'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:42:31.959211Z","iopub.execute_input":"2024-11-04T08:42:31.959645Z","iopub.status.idle":"2024-11-04T08:42:32.125173Z","shell.execute_reply.started":"2024-11-04T08:42:31.959609Z","shell.execute_reply":"2024-11-04T08:42:32.124156Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Image feature extraction","metadata":{}},{"cell_type":"code","source":"# images = []\n\n# for key, item in train_json.items():\n#     images.append(item['image'])\n\n# for key, item in dev_json.items():\n#     images.append(item['image'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:42:32.127828Z","iopub.execute_input":"2024-11-04T08:42:32.128125Z","iopub.status.idle":"2024-11-04T08:42:32.132205Z","shell.execute_reply.started":"2024-11-04T08:42:32.128100Z","shell.execute_reply":"2024-11-04T08:42:32.131388Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# source_all = ['/kaggle/input/dsc24-vimmsd/dev-images/dev-images',\n#               '/kaggle/input/dsc24-vimmsd/train-images/train-images']\n\n# destination = './images'\n# #os.mkdir(destination)\n\n# for source in source_all:\n#     allfiles = os.listdir(source)\n#     for f in allfiles:\n#         src_path = os.path.join(source, f)\n#         dst_path = os.path.join(destination, f)\n#         shutil.copy(src_path, dst_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:42:32.133276Z","iopub.execute_input":"2024-11-04T08:42:32.133627Z","iopub.status.idle":"2024-11-04T08:42:32.142667Z","shell.execute_reply.started":"2024-11-04T08:42:32.133602Z","shell.execute_reply":"2024-11-04T08:42:32.141810Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## BEiT","metadata":{}},{"cell_type":"code","source":"# model = timm.create_model(\n#     'beitv2_base_patch16_224.in1k_ft_in22k_in1k',\n#     pretrained=True,\n#     num_classes=0,  # remove classifier nn.Linear\n# ).to('cuda')\n\n# model = model.eval()\n# data_config = timm.data.resolve_model_data_config(model)\n# transforms = timm.data.create_transform(**data_config, is_training=False)\n\n# img_w = {}\n\n# def batch(iterable, n=1):\n#     l = len(iterable)\n#     for ndx in range(0, l, n):\n#         yield iterable[ndx:min(ndx + n, l)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:42:32.143785Z","iopub.execute_input":"2024-11-04T08:42:32.145474Z","iopub.status.idle":"2024-11-04T08:42:32.152601Z","shell.execute_reply.started":"2024-11-04T08:42:32.145449Z","shell.execute_reply":"2024-11-04T08:42:32.151844Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# p = '/kaggle/working/images/'\n\n# img_w = {}\n\n# # get features for images, we will do this 3 images at a time to reduce time\n\n# for x in tqdm.notebook.tqdm(batch(images, 3),total=int(len(images)/3)):\n#     img = [Image.open(p + v).convert('RGB') for v in x]\n#     print(x)\n\n#     with torch.no_grad():\n#         img  = torch.stack([transforms(i) for i in img]).to('cuda')\n#         output = model.forward_features(img)[:,1:,:]\n\n#     tmp_img_w = {k:v for k,v in zip(x,output)}\n\n#     img_w.update(tmp_img_w)\n\n#     del output\n#     del tmp_img_w\n#     del img\n#     torch.cuda.empty_cache()\n\n# torch.save(img_w, '/kaggle/working/beitv2-b-p.pt') # export for later used\n# FileLink('/kaggle/working/beitv2-b-p.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:42:32.153621Z","iopub.execute_input":"2024-11-04T08:42:32.153897Z","iopub.status.idle":"2024-11-04T08:42:32.162278Z","shell.execute_reply.started":"2024-11-04T08:42:32.153875Z","shell.execute_reply":"2024-11-04T08:42:32.161590Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Load extracted image features","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.nn.functional import normalize\n\nimg_w = torch.load('/kaggle/input/dsc24-vit/vit-b.pt')\n# img_w = torch.load('/kaggle/input/lovecat-beitv2-b-p/beitv2-b-p.pt') # already-saved features\nlen(img_w)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:42:32.163181Z","iopub.execute_input":"2024-11-04T08:42:32.163448Z","iopub.status.idle":"2024-11-04T08:43:22.374173Z","shell.execute_reply.started":"2024-11-04T08:42:32.163427Z","shell.execute_reply":"2024-11-04T08:43:22.373330Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"12218"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"img_w['ac7931bb887ad853b41675f07595bf04469970d1b099ffc8806a4ceaac7d7940.jpg'].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:43:22.375271Z","iopub.execute_input":"2024-11-04T08:43:22.375555Z","iopub.status.idle":"2024-11-04T08:43:22.382385Z","shell.execute_reply.started":"2024-11-04T08:43:22.375531Z","shell.execute_reply":"2024-11-04T08:43:22.381526Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"torch.Size([196, 768])"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer\n\nfrom utils import T5ForConditionalGeneration\n\ntokenizer = T5Tokenizer.from_pretrained(\"VietAI/vit5-base\")\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"VietAI/vit5-base\").to('cuda')\n\nmodel.add_imgw(img_w)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:43:22.383461Z","iopub.execute_input":"2024-11-04T08:43:22.383809Z","iopub.status.idle":"2024-11-04T08:43:41.213936Z","shell.execute_reply.started":"2024-11-04T08:43:22.383778Z","shell.execute_reply":"2024-11-04T08:43:41.213031Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab8f8dd4e77c4326807edde0ebb0049e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3e2d11b5f8e40a59d4fe1879730bee7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35892fb737ee4fa4af6d1cc139cf8d69"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62b33d1946e0439d9a55a766a9a113fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/904M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a435fc0bab34fa8b3a867bb43aa3d74"}},"metadata":{}},{"name":"stderr","text":"Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at VietAI/vit5-base and are newly initialized: ['resize_img_dim.weight', 'resize_img_dim.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Prepare datasets","metadata":{}},{"cell_type":"code","source":"emoji_file_path = '/kaggle/input/datasets-preprocesing/emoji_to_vietnamese.json'\nstopword_path = '/kaggle/input/datasets-preprocesing/vietnamese-stopwords.txt'\n\ndef load_resources(stopword_path, emoji_file_path):\n    # Đọc stopword từ file txt\n    with open(stopword_path, 'r', encoding='utf-8') as f:\n        stopwords = set(f.read().splitlines())\n\n    # Đọc emoji từ file JSON\n    with open(emoji_file_path, 'r', encoding='utf-8') as emoji_file:\n        emoji_dict = json.load(emoji_file)\n\n    return stopwords, emoji_dict\n\nstopwords, emoji_dict = load_resources(stopword_path, emoji_file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:43:41.215113Z","iopub.execute_input":"2024-11-04T08:43:41.215728Z","iopub.status.idle":"2024-11-04T08:43:41.231597Z","shell.execute_reply.started":"2024-11-04T08:43:41.215699Z","shell.execute_reply":"2024-11-04T08:43:41.230854Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.DataFrame(train_json).T\ntest_df = pd.DataFrame(dev_json).T # public test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:43:41.232718Z","iopub.execute_input":"2024-11-04T08:43:41.233380Z","iopub.status.idle":"2024-11-04T08:43:41.701120Z","shell.execute_reply.started":"2024-11-04T08:43:41.233347Z","shell.execute_reply":"2024-11-04T08:43:41.700354Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_df['image_id'] = train_df['image'].astype(str)\ntest_df['image_id'] = test_df['image'].astype(str)\n\ntrain_df['caption'] = train_df['caption'].astype(str)\ntest_df['caption'] = test_df['caption'].astype(str)\n\ntrain_df['label'] = train_df['label'].astype(str)\ntest_df['label'] = test_df['label'].astype(str)\n\ntrain_df.drop(columns=['image'], inplace=True)\ntest_df.drop(columns=['image'], inplace=True)\n\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:43:41.706662Z","iopub.execute_input":"2024-11-04T08:43:41.707004Z","iopub.status.idle":"2024-11-04T08:43:41.738098Z","shell.execute_reply.started":"2024-11-04T08:43:41.706980Z","shell.execute_reply":"2024-11-04T08:43:41.737225Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                             caption          label  \\\n0            Cô ấy trên mạng vs cô ấy ngoài đời =)))  multi-sarcasm   \n1    Người tâm linh giao tiếp với người thực tế :)))    not-sarcasm   \n2  Hình như Trăng hôm nay đẹp quá mọi người ạ! 😃 ...  multi-sarcasm   \n3  MỌI NGƯỜI NGHĨ SAO VỀ PHÁT BIỂU CỦA SHARK VIỆT...    not-sarcasm   \n4        2 tay hai nàng chứ việc gì phải lệ hai hàng  multi-sarcasm   \n\n                                            image_id  \n0  8ae451edcd8ebf697f8763ece249115813149c55733bf8...  \n1  35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...  \n2  316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...  \n3  8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...  \n4  e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>label</th>\n      <th>image_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cô ấy trên mạng vs cô ấy ngoài đời =)))</td>\n      <td>multi-sarcasm</td>\n      <td>8ae451edcd8ebf697f8763ece249115813149c55733bf8...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Người tâm linh giao tiếp với người thực tế :)))</td>\n      <td>not-sarcasm</td>\n      <td>35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hình như Trăng hôm nay đẹp quá mọi người ạ! 😃 ...</td>\n      <td>multi-sarcasm</td>\n      <td>316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MỌI NGƯỜI NGHĨ SAO VỀ PHÁT BIỂU CỦA SHARK VIỆT...</td>\n      <td>not-sarcasm</td>\n      <td>8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2 tay hai nàng chứ việc gì phải lệ hai hàng</td>\n      <td>multi-sarcasm</td>\n      <td>e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"### Features enrichment","metadata":{}},{"cell_type":"code","source":"!gdown 1q7_-PEQQ6IR3Ortz45vEiSiOnweRJ40H # cap train\n!gdown 1wldmw8IJgX-nK2_yfo8fLx55KfWGIZhp # cap dev ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:43:41.739350Z","iopub.execute_input":"2024-11-04T08:43:41.739680Z","iopub.status.idle":"2024-11-04T08:43:56.677281Z","shell.execute_reply.started":"2024-11-04T08:43:41.739650Z","shell.execute_reply":"2024-11-04T08:43:56.676368Z"}},"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1q7_-PEQQ6IR3Ortz45vEiSiOnweRJ40H\nTo: /kaggle/working/vi_train_captions.json\n100%|███████████████████████████████████████| 11.3M/11.3M [00:00<00:00, 170MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1wldmw8IJgX-nK2_yfo8fLx55KfWGIZhp\nTo: /kaggle/working/vi_dev_captions.json\n100%|███████████████████████████████████████| 1.14M/1.14M [00:00<00:00, 111MB/s]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!gdown 1AnM0RUMfyGYWaiUgafufEKMjB8zo5dUt # object reg train\n!gdown 1sk2vJutRJLCUwQ6ZKJQeYFKpvdkjUiBs # object reg dev","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:43:56.678951Z","iopub.execute_input":"2024-11-04T08:43:56.679600Z","iopub.status.idle":"2024-11-04T08:44:07.099040Z","shell.execute_reply.started":"2024-11-04T08:43:56.679562Z","shell.execute_reply":"2024-11-04T08:44:07.098015Z"}},"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1AnM0RUMfyGYWaiUgafufEKMjB8zo5dUt\nTo: /kaggle/working/objects-recognition-train.json\n100%|███████████████████████████████████████| 2.49M/2.49M [00:00<00:00, 184MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1sk2vJutRJLCUwQ6ZKJQeYFKpvdkjUiBs\nTo: /kaggle/working/objects-recognition-dev.json\n100%|█████████████████████████████████████████| 317k/317k [00:00<00:00, 107MB/s]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!gdown 1nh3y-lXq2CEc_rwzeTqGIU69VZA4eVEn # OCR dev\n!gdown 1YSn-dWwprc0nhOgRUIj5aFPaW9lxKWZT","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:07.100818Z","iopub.execute_input":"2024-11-04T08:44:07.101725Z","iopub.status.idle":"2024-11-04T08:44:17.189874Z","shell.execute_reply.started":"2024-11-04T08:44:07.101685Z","shell.execute_reply":"2024-11-04T08:44:17.188888Z"}},"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1nh3y-lXq2CEc_rwzeTqGIU69VZA4eVEn\nTo: /kaggle/working/ocr-results-dev.json\n100%|█████████████████████████████████████████| 669k/669k [00:00<00:00, 110MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1YSn-dWwprc0nhOgRUIj5aFPaW9lxKWZT\nTo: /kaggle/working/ocr-results-train.json\n100%|███████████████████████████████████████| 4.06M/4.06M [00:00<00:00, 183MB/s]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"\n# Open JSON files with utf-8 encoding to handle non-ASCII characters\nwith open('/kaggle/working/vi_train_captions.json', encoding='utf-8') as f:\n    cap_train = json.load(f)\n\nwith open('/kaggle/working/vi_dev_captions.json', encoding='utf-8') as f:\n    cap_test = json.load(f)\n\nwith open('/kaggle/working/objects-recognition-train.json', encoding='utf-8') as f:\n    obj_train = json.load(f)\n\nwith open('/kaggle/working/objects-recognition-dev.json', encoding='utf-8') as f:\n    obj_test = json.load(f)\n\nwith open('/kaggle/working/ocr-results-dev.json', encoding='utf-8') as f:\n    ocr_test = json.load(f)\n\nwith open('/kaggle/working/ocr-results-train.json', encoding='utf-8') as f:\n    ocr_train = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:17.191252Z","iopub.execute_input":"2024-11-04T08:44:17.191591Z","iopub.status.idle":"2024-11-04T08:44:17.374744Z","shell.execute_reply.started":"2024-11-04T08:44:17.191563Z","shell.execute_reply":"2024-11-04T08:44:17.373877Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def json_to_df(json):\n    df = pd.DataFrame(json)\n    df['image_id'] = df['image'].astype(str)\n    df.drop(columns=['image'], inplace=True)\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:17.375873Z","iopub.execute_input":"2024-11-04T08:44:17.376174Z","iopub.status.idle":"2024-11-04T08:44:17.381613Z","shell.execute_reply.started":"2024-11-04T08:44:17.376149Z","shell.execute_reply":"2024-11-04T08:44:17.380566Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"for item in ocr_train:\n    item[\"OCR\"] = \", \".join(item[\"OCR\"])\nfor item in ocr_test:\n    item[\"OCR\"] = \", \".join(item[\"OCR\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:17.382737Z","iopub.execute_input":"2024-11-04T08:44:17.383009Z","iopub.status.idle":"2024-11-04T08:44:17.403858Z","shell.execute_reply.started":"2024-11-04T08:44:17.382986Z","shell.execute_reply":"2024-11-04T08:44:17.403076Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"cap_test_df = json_to_df(cap_test)\n\ncap_train_df = json_to_df(cap_train)\n\nobj_train_df = json_to_df(obj_train)\n\nobj_test_df = json_to_df(obj_test)\n\nocr_train_df = json_to_df(ocr_train)\n\nocr_test_df = json_to_df(ocr_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:17.404991Z","iopub.execute_input":"2024-11-04T08:44:17.405227Z","iopub.status.idle":"2024-11-04T08:44:17.454950Z","shell.execute_reply.started":"2024-11-04T08:44:17.405207Z","shell.execute_reply":"2024-11-04T08:44:17.454221Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"obj_train_df['object_recognition'] = obj_train_df['object_recognition'].apply(lambda x: \"Trong hình có \" + x + \". \" if len(x) > 0 else \"\")\nobj_test_df['object_recognition'] = obj_test_df['object_recognition'].apply(lambda x: \"Trong hình có \" + x + \". \" if len(x) > 0 else \"\")\nobj_test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:17.456044Z","iopub.execute_input":"2024-11-04T08:44:17.456364Z","iopub.status.idle":"2024-11-04T08:44:17.477233Z","shell.execute_reply.started":"2024-11-04T08:44:17.456334Z","shell.execute_reply":"2024-11-04T08:44:17.476094Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                                  object_recognition  \\\n0  Trong hình có người, đồ vật, phim hoạt hình, đ...   \n1  Trong hình có truyện, người, dải, phim hoạt hì...   \n2                       Trong hình có số, ghi, chữ.    \n3               Trong hình có diều, người, văn bản.    \n4  Trong hình có suv, xe thể, quảng cáo, xe hơi, ...   \n\n                                            image_id  \n0  2d06d8c77c741d001916199346cc112847e6bcf61b3dce...  \n1  c981f23fc77cebd06ea872ea2c0ff6ec43a9d2517366ed...  \n2  342c9a8f91adeacde0f2c26dee3e6b86861b43e948d10b...  \n3  2aa95c65c0a6444caff0657ed21e27fbc403af1727749a...  \n4  9d6ebb26087b8d6051f77ef7cbf3e9a0d750baa41b45d7...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>object_recognition</th>\n      <th>image_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Trong hình có người, đồ vật, phim hoạt hình, đ...</td>\n      <td>2d06d8c77c741d001916199346cc112847e6bcf61b3dce...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Trong hình có truyện, người, dải, phim hoạt hì...</td>\n      <td>c981f23fc77cebd06ea872ea2c0ff6ec43a9d2517366ed...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Trong hình có số, ghi, chữ.</td>\n      <td>342c9a8f91adeacde0f2c26dee3e6b86861b43e948d10b...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trong hình có diều, người, văn bản.</td>\n      <td>2aa95c65c0a6444caff0657ed21e27fbc403af1727749a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trong hình có suv, xe thể, quảng cáo, xe hơi, ...</td>\n      <td>9d6ebb26087b8d6051f77ef7cbf3e9a0d750baa41b45d7...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"ocr_train_df['OCR'] = ocr_train_df['OCR'].apply(lambda row: \"Chữ trong hình là \" + row + \". \" if len(row) > 0 else \"\")\nocr_test_df['OCR'] = ocr_test_df['OCR'].apply(lambda row: \"Chữ trong hình là \" + row + \". \" if len(row) > 0 else \"\")\n\n# cap_train_df['caption'] = cap_train_df['caption'].apply(lambda row: row[:150] if len(row) > 150 else row)\n# cap_test_df['caption'] = cap_test_df['caption'].apply(lambda row: row[:150] if len(row) > 150 else row)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:17.478369Z","iopub.execute_input":"2024-11-04T08:44:17.478648Z","iopub.status.idle":"2024-11-04T08:44:17.495707Z","shell.execute_reply.started":"2024-11-04T08:44:17.478625Z","shell.execute_reply":"2024-11-04T08:44:17.494810Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def enrich(df1, df2, add_field):\n    temp = df2.set_index('image_id')\n    \n    df1['caption'] = df1.apply(\n        lambda row: row['caption'] + ' ' + temp.loc[row['image_id'], add_field]\n        if row['image_id'] in temp.index else row['caption'], axis=1\n    )\n\n    return df1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:17.496877Z","iopub.execute_input":"2024-11-04T08:44:17.497114Z","iopub.status.idle":"2024-11-04T08:44:17.506297Z","shell.execute_reply.started":"2024-11-04T08:44:17.497093Z","shell.execute_reply":"2024-11-04T08:44:17.505461Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"train_df['caption'] = train_df['caption'].apply(lambda x: x[:150] if len(x) > 150 else x)\ntest_df['caption'] = test_df['caption'].apply(lambda x: x[:150] if len(x) > 150 else x)\n\ntrain_df = enrich(train_df, ocr_train_df, 'OCR')\ntest_df = enrich(test_df, ocr_test_df, 'OCR')\n\ntrain_df = enrich(train_df, cap_train_df, 'caption')\ntest_df = enrich(test_df, cap_test_df, 'caption')\n\n# train_df = enrich(train_df, obj_train_df, 'object_recognition')\n# test_df = enrich(test_df, obj_test_df, 'object_recognition')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:17.507415Z","iopub.execute_input":"2024-11-04T08:44:17.507976Z","iopub.status.idle":"2024-11-04T08:44:32.054520Z","shell.execute_reply.started":"2024-11-04T08:44:17.507946Z","shell.execute_reply":"2024-11-04T08:44:32.053737Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:32.055747Z","iopub.execute_input":"2024-11-04T08:44:32.056023Z","iopub.status.idle":"2024-11-04T08:44:32.065539Z","shell.execute_reply.started":"2024-11-04T08:44:32.055999Z","shell.execute_reply":"2024-11-04T08:44:32.064648Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                             caption          label  \\\n0  Cô ấy trên mạng vs cô ấy ngoài đời =)))  Bức ả...  multi-sarcasm   \n1  Người tâm linh giao tiếp với người thực tế :))...    not-sarcasm   \n2  Hình như Trăng hôm nay đẹp quá mọi người ạ! 😃 ...  multi-sarcasm   \n3  MỌI NGƯỜI NGHĨ SAO VỀ PHÁT BIỂU CỦA SHARK VIỆT...    not-sarcasm   \n4  2 tay hai nàng chứ việc gì phải lệ hai hàng  H...  multi-sarcasm   \n\n                                            image_id  \n0  8ae451edcd8ebf697f8763ece249115813149c55733bf8...  \n1  35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...  \n2  316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...  \n3  8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...  \n4  e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>label</th>\n      <th>image_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cô ấy trên mạng vs cô ấy ngoài đời =)))  Bức ả...</td>\n      <td>multi-sarcasm</td>\n      <td>8ae451edcd8ebf697f8763ece249115813149c55733bf8...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Người tâm linh giao tiếp với người thực tế :))...</td>\n      <td>not-sarcasm</td>\n      <td>35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hình như Trăng hôm nay đẹp quá mọi người ạ! 😃 ...</td>\n      <td>multi-sarcasm</td>\n      <td>316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MỌI NGƯỜI NGHĨ SAO VỀ PHÁT BIỂU CỦA SHARK VIỆT...</td>\n      <td>not-sarcasm</td>\n      <td>8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2 tay hai nàng chứ việc gì phải lệ hai hàng  H...</td>\n      <td>multi-sarcasm</td>\n      <td>e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"### Text preprocessing","metadata":{}},{"cell_type":"code","source":"import re\ndef preprocess_text(text):\n    def remove_stopwords(text):\n        return text\n    def replace_emojis(text):\n        for emoji, description in emoji_dict.get('emoji', {}).items():\n            text = text.replace(emoji, description)  # Thay thế emoji bằng mô tả\n        return text\n\n    def replace_emoticons(text):\n        for emoticon, meaning in emoji_dict.get('biểu_tượng', {}).items():\n            emoticon_pattern = re.escape(emoticon) + r\"{1,}\"\n            text = re.sub(emoticon_pattern, meaning, text)\n        return text\n\n    def normalize_text(text):\n        text = text.lower()  # Chuyển thành chữ thường\n        text = re.sub(r'(?<=\\w)[\\/\\.\\-\\_,\\\\](?=\\w)', '', text)  # Loại bỏ dấu chấm hoặc gạch nối trong từ\n        return text\n\n    text = replace_emojis(text)       # Thay thế emoji\n    text = replace_emoticons(text)    # Thay thế biểu cảm\n    text = normalize_text(text)       # Chuẩn hóa văn bản\n    text = remove_stopwords(text)\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:32.066635Z","iopub.execute_input":"2024-11-04T08:44:32.066930Z","iopub.status.idle":"2024-11-04T08:44:32.075771Z","shell.execute_reply.started":"2024-11-04T08:44:32.066905Z","shell.execute_reply":"2024-11-04T08:44:32.074952Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"train_df['caption'] = train_df['caption'].astype(str)\ntest_df['caption'] = test_df['caption'].astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:32.076821Z","iopub.execute_input":"2024-11-04T08:44:32.077108Z","iopub.status.idle":"2024-11-04T08:44:32.170328Z","shell.execute_reply.started":"2024-11-04T08:44:32.077085Z","shell.execute_reply":"2024-11-04T08:44:32.169507Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"train_df['caption'] = train_df['caption'].apply(preprocess_text)\ntest_df['caption'] = test_df['caption'].apply(preprocess_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:32.171925Z","iopub.execute_input":"2024-11-04T08:44:32.172222Z","iopub.status.idle":"2024-11-04T08:44:33.900913Z","shell.execute_reply.started":"2024-11-04T08:44:32.172199Z","shell.execute_reply":"2024-11-04T08:44:33.899775Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"train_df['caption'].iloc[2003]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:33.902640Z","iopub.execute_input":"2024-11-04T08:44:33.903105Z","iopub.status.idle":"2024-11-04T08:44:33.912098Z","shell.execute_reply.started":"2024-11-04T08:44:33.903073Z","shell.execute_reply":"2024-11-04T08:44:33.910722Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'may mà gặp được tôi chữ trong hình là trờl olll_, làm sao thế này?!?, cậu bạn này đang vẽ dở, thỉ lăn đùng ra (o giật, sùl bọt mép!, nguy quá!, để tôl glúp!, 1.  hình ảnh mô tả một dải truyện tranh có một nhân vật hoạt hình và một người đang vẽ trên giá vẽ. nhân vật hoạt hình đang cầm một cây cọ vẽ trên một tay và một cây cọ trên tay kia, trong khi người đó đang ngồi trên giá vẽ với nụ cười trên môi. nội dung của hình ảnh có thể mang tính châm biếm, vì người đó đang cố gắng trêu chọc nỗ lực vẽ của người khác. tuy nhiên, nó cũng có thể mang tính giải trí, vì người đó dường như đang có một khoảng thời gian vui vẻ khi vẽ trên giá vẽ. nhìn chung, nội dung của hình ảnh có thể được coi là châm biếm hoặc giải trí, tùy thuộc vào quan điểm của người đó.'"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nX = train_df.drop(columns=['label'])  # Features\ny = train_df['label']  # Labels\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n\ntrain_df = pd.concat([X_train, y_train], axis=1)\nval_df = pd.concat([X_test, y_test], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:33.913728Z","iopub.execute_input":"2024-11-04T08:44:33.914763Z","iopub.status.idle":"2024-11-04T08:44:34.297702Z","shell.execute_reply.started":"2024-11-04T08:44:33.914730Z","shell.execute_reply":"2024-11-04T08:44:34.296912Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"print(train_df.shape, val_df.shape, test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:34.298930Z","iopub.execute_input":"2024-11-04T08:44:34.299272Z","iopub.status.idle":"2024-11-04T08:44:34.304476Z","shell.execute_reply.started":"2024-11-04T08:44:34.299241Z","shell.execute_reply":"2024-11-04T08:44:34.303588Z"}},"outputs":[{"name":"stdout","text":"(9724, 3) (1081, 3) (1413, 3)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"### Convert to Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, TrainingArguments, Seq2SeqTrainingArguments\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import DataLoader\n\ndef preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"inputs\"], max_length=400, truncation=True, padding=True\n    )\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"labels\"], max_length=32, truncation=True, padding=True\n        )\n    model_inputs['labels'] = labels['input_ids']\n    model_inputs['input_ids'] = model_inputs['input_ids']\n    model_inputs[\"image_id\"] = examples[\"image_id\"]\n    \n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:34.305689Z","iopub.execute_input":"2024-11-04T08:44:34.305950Z","iopub.status.idle":"2024-11-04T08:44:34.800779Z","shell.execute_reply.started":"2024-11-04T08:44:34.305928Z","shell.execute_reply":"2024-11-04T08:44:34.799985Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"dict_obj = {}\n\ndict_obj['inputs'] = train_df['caption'].astype(str).tolist()  # Convert Series to list\ndict_obj['labels'] = train_df['label'].astype(str).tolist()    # Convert Series to list\ndict_obj['image_id'] = train_df['image_id'].astype(str).tolist()\ntrain_dataset = Dataset.from_dict(dict_obj)\ntokenized_train_datasets = train_dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)\n\ndict_obj = {}\ndict_obj['inputs'] = val_df['caption'].astype(str).tolist()  # Convert Series to list\ndict_obj['labels'] = val_df['label'].astype(str).tolist()    # Convert Series to list\ndict_obj['image_id'] = val_df['image_id'].astype(str).tolist()\nval_dataset = Dataset.from_dict(dict_obj)\ntokenized_val_datasets = val_dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:34.801858Z","iopub.execute_input":"2024-11-04T08:44:34.802854Z","iopub.status.idle":"2024-11-04T08:44:46.174908Z","shell.execute_reply.started":"2024-11-04T08:44:34.802826Z","shell.execute_reply":"2024-11-04T08:44:46.173902Z"}},"outputs":[{"name":"stdout","text":"         ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b58e28a8ea04a5181839c4c0e778827"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b3d60411b084a3e9524c254b4d5d82f"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95f8029e9bf34f83b0e6a789f0e9f933"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7e8f2eb6c14f92be0b1a88cf1231eb"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a68f06b8109d4e54ba9d19c19d0bdb84"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a19f0cca5e9443b2956867a1679f1139"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c17116c3362b480da7a97a2c93a8167f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf0495277074479a8ba7ff35ae31032b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"          ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27e906086a0f4dac96014f72cd0e3efc"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c03fa018c1442c2bb5e08692a0ab73e"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df1942d8225348bb92d60030551110d7"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb30e52e9be1485ea4966aa8bdcb38d8"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6e0ab8616554c58857e558ec6886c46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bc0ae4a106549d0be111323e114c928"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b1bb480c44c4d1bab8238fc3388b3c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a52287020c4a408f9709dc5f84a8a1d7"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"import random\n\nimport numpy as np\n\nimport torch\n\ndef set_SEED():\n    SEED = 42\n    random.seed(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.enabled = False\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:46.176670Z","iopub.execute_input":"2024-11-04T08:44:46.177534Z","iopub.status.idle":"2024-11-04T08:44:46.183827Z","shell.execute_reply.started":"2024-11-04T08:44:46.177490Z","shell.execute_reply":"2024-11-04T08:44:46.182835Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"import os\nfrom transformers.optimization import Adafactor, AdafactorSchedule\nfrom transformers import DataCollatorForSeq2Seq\nfrom utils import DataCollatorForSeq2Seq\n\nos.environ[\"WANDB_DISABLED\"] = \"True\"\nset_SEED()\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n\n#Adam\ntraining_args = Seq2SeqTrainingArguments(output_dir=\"./checkpoint\",\n                                      do_train=True,\n                                      do_eval=True,\n                                      num_train_epochs=2,\n                                      learning_rate=2.5e-5,\n                                      warmup_ratio=0.05,\n                                      weight_decay=0.01,\n                                      per_device_train_batch_size=8,\n                                      per_device_eval_batch_size=8,\n                                      logging_dir='./log',\n                                      group_by_length=True,\n                                      save_strategy=\"steps\",\n                                      evaluation_strategy=\"steps\",\n                                      save_total_limit=5,\n                                      eval_steps=100,\n                                      logging_steps = 100,\n                                      save_steps=100,\n                                      load_best_model_at_end= True,\n                                      fp16=True,\n                                      seed=42,\n                                      )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:46.185032Z","iopub.execute_input":"2024-11-04T08:44:46.185329Z","iopub.status.idle":"2024-11-04T08:44:46.202690Z","shell.execute_reply.started":"2024-11-04T08:44:46.185285Z","shell.execute_reply":"2024-11-04T08:44:46.201879Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"tokenized_train_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:46.203802Z","iopub.execute_input":"2024-11-04T08:44:46.204064Z","iopub.status.idle":"2024-11-04T08:44:46.212423Z","shell.execute_reply.started":"2024-11-04T08:44:46.204042Z","shell.execute_reply":"2024-11-04T08:44:46.211596Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'image_id', 'input_ids', 'attention_mask'],\n    num_rows: 9724\n})"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"tokenized_val_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:46.213415Z","iopub.execute_input":"2024-11-04T08:44:46.213648Z","iopub.status.idle":"2024-11-04T08:44:46.227107Z","shell.execute_reply.started":"2024-11-04T08:44:46.213627Z","shell.execute_reply":"2024-11-04T08:44:46.226233Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'image_id', 'input_ids', 'attention_mask'],\n    num_rows: 1081\n})"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model = model,\n    args = training_args,\n    train_dataset=tokenized_train_datasets,\n    eval_dataset=tokenized_val_datasets,\n    data_collator=data_collator,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T08:44:46.228533Z","iopub.execute_input":"2024-11-04T08:44:46.229057Z","iopub.status.idle":"2024-11-04T09:16:08.532285Z","shell.execute_reply.started":"2024-11-04T08:44:46.229026Z","shell.execute_reply":"2024-11-04T09:16:08.531373Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2432' max='2432' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2432/2432 31:14, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>6.119200</td>\n      <td>0.193678</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.165800</td>\n      <td>0.129950</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.147700</td>\n      <td>0.124674</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.135100</td>\n      <td>0.141539</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.129800</td>\n      <td>0.109040</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.116300</td>\n      <td>0.111312</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.114900</td>\n      <td>0.107218</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.123300</td>\n      <td>0.120326</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.115600</td>\n      <td>0.103290</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.113800</td>\n      <td>0.112908</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.107000</td>\n      <td>0.120452</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.103600</td>\n      <td>0.105675</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.098600</td>\n      <td>0.109471</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.097500</td>\n      <td>0.105179</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.104600</td>\n      <td>0.104733</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.099600</td>\n      <td>0.108686</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.094500</td>\n      <td>0.108540</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.098300</td>\n      <td>0.105805</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.095200</td>\n      <td>0.105798</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.086500</td>\n      <td>0.106613</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.098300</td>\n      <td>0.106190</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.089400</td>\n      <td>0.107119</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.094600</td>\n      <td>0.106444</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.090700</td>\n      <td>0.105746</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2432, training_loss=0.35625073637225124, metrics={'train_runtime': 1875.9361, 'train_samples_per_second': 10.367, 'train_steps_per_second': 1.296, 'total_flos': 9289096667136000.0, 'train_loss': 0.35625073637225124, 'epoch': 2.0})"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport json\n\n# save loss\nlog_history = {'log_history':trainer.state.log_history}\n\nwith open('logs.json', 'w', encoding='utf-8') as f:\n    json.dump(log_history, f, ensure_ascii=False, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T09:16:08.533559Z","iopub.execute_input":"2024-11-04T09:16:08.533861Z","iopub.status.idle":"2024-11-04T09:16:08.540319Z","shell.execute_reply.started":"2024-11-04T09:16:08.533836Z","shell.execute_reply":"2024-11-04T09:16:08.539359Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"from matplotlib import pyplot\n\ntrain_loss = {i['step']:i['loss'] for i in log_history['log_history'] if 'loss' in i.keys()}\neval_loss = {i['step']:i['eval_loss'] for i in log_history['log_history'] if 'eval_loss' in i.keys()}\nplt.plot(list(train_loss.values()))\nplt.plot(list(eval_loss.values()))\n\nplt.yscale('log')\nplt.legend(['train','val'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T09:16:08.553641Z","iopub.execute_input":"2024-11-04T09:16:08.553891Z","iopub.status.idle":"2024-11-04T09:16:09.098233Z","shell.execute_reply.started":"2024-11-04T09:16:08.553869Z","shell.execute_reply":"2024-11-04T09:16:09.095970Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x78623ed50340>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"# Load checkpoints and predict\n\n","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()\nmodel = T5ForConditionalGeneration.from_pretrained(\"/kaggle/working/checkpoint/checkpoint-2200\")\nmodel.to('cuda')\nmodel.add_imgw(img_w)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T09:37:59.837213Z","iopub.execute_input":"2024-11-04T09:37:59.838152Z","iopub.status.idle":"2024-11-04T09:38:03.180136Z","shell.execute_reply.started":"2024-11-04T09:37:59.838118Z","shell.execute_reply":"2024-11-04T09:38:03.179330Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"from datasets import Dataset\n\ndict_obj = {}\ndict_obj['inputs'] = test_df['caption']\ndict_obj['labels'] =  test_df['label']\ndict_obj['image_id'] = test_df['image_id']\ntest_dataset = Dataset.from_dict(dict_obj)\ntokenized_test_datasets = test_dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T09:38:03.181749Z","iopub.execute_input":"2024-11-04T09:38:03.182036Z","iopub.status.idle":"2024-11-04T09:38:05.861316Z","shell.execute_reply.started":"2024-11-04T09:38:03.182010Z","shell.execute_reply":"2024-11-04T09:38:05.860279Z"}},"outputs":[{"name":"stdout","text":"          ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e957564fb9004983acf88929e20c1808"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ccdd18544794538a93513641e80a8ff"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb97d2ce099649b6be52c3c1fb77ca56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c6ad4c23bcd4a3e97c272e1c4317aa9"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec85af1676b042f6b973202c62ec1d23"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a8e5a5f159c46dfa6933f1d7441b333"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fc4e650f5904c51929db2a050c3b409"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14021fcdd15b475a8a0ccc367b67cdc9"}},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T09:38:05.862914Z","iopub.execute_input":"2024-11-04T09:38:05.863270Z","iopub.status.idle":"2024-11-04T09:38:06.254782Z","shell.execute_reply.started":"2024-11-04T09:38:05.863241Z","shell.execute_reply":"2024-11-04T09:38:06.253855Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"34"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"tokenized_test_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T09:38:06.257226Z","iopub.execute_input":"2024-11-04T09:38:06.257536Z","iopub.status.idle":"2024-11-04T09:38:06.267974Z","shell.execute_reply.started":"2024-11-04T09:38:06.257510Z","shell.execute_reply":"2024-11-04T09:38:06.267164Z"}},"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'image_id', 'input_ids', 'attention_mask'],\n    num_rows: 1413\n})"},"metadata":{}}],"execution_count":74},{"cell_type":"code","source":"import torch \nimport numpy as np\nfrom datasets import load_metric\nmetrics = load_metric('accuracy')\n\ntorch.cuda.empty_cache()\nmax_target_length = 10\ndataloader = torch.utils.data.DataLoader(tokenized_test_datasets, collate_fn=data_collator, batch_size=4) #replace tokenized_dev_datasets with tokenized_test_datasets\n\npredictions = []\nreferences = []\n\nfor i, batch in enumerate(tqdm(dataloader)):\n    # greedy search\n    outputs = model.generate(image_id = batch['image_id'],\n        input_ids=batch['input_ids'].to('cuda'),\n        max_length=max_target_length,\n        attention_mask=batch['attention_mask'].to('cuda'),\n        return_dict_in_generate=True, output_attentions=True,)\n\n    #beam search for now   \n    # outputs = model.generate(\n    #     image_id = np.repeat(batch['image_id'], 7),\n    #     input_ids=batch['input_ids'].to('cuda'),\n    #     max_length=max_target_length,\n    #     attention_mask=batch['attention_mask'].to('cuda'),\n    #     return_dict_in_generate=True, output_attentions=True,\n    #     num_beams=7,\n    #     no_repeat_ngram_size=2)\n    \n    with tokenizer.as_target_tokenizer():\n        outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs.sequences]\n        labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n        # actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n\n    predictions.extend(outputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T09:38:06.269163Z","iopub.execute_input":"2024-11-04T09:38:06.269510Z","iopub.status.idle":"2024-11-04T09:39:20.213834Z","shell.execute_reply.started":"2024-11-04T09:38:06.269479Z","shell.execute_reply":"2024-11-04T09:39:20.212889Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/354 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a17ef843f814c6f808fb00a9bf8eda8"}},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"len(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T09:39:20.215042Z","iopub.execute_input":"2024-11-04T09:39:20.215370Z","iopub.status.idle":"2024-11-04T09:39:20.222409Z","shell.execute_reply.started":"2024-11-04T09:39:20.215302Z","shell.execute_reply":"2024-11-04T09:39:20.221521Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"1413"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"def postprocessing(t):\n    t = t.lower()\n    t = t.replace('\\\\','')\n    return t\n\ntest_predicted = {k:postprocessing(i) for k,i in zip(dev_json.keys(),predictions)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T09:39:20.223557Z","iopub.execute_input":"2024-11-04T09:39:20.223859Z","iopub.status.idle":"2024-11-04T09:39:20.237114Z","shell.execute_reply.started":"2024-11-04T09:39:20.223825Z","shell.execute_reply":"2024-11-04T09:39:20.236334Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"result_json = {\n    \"results\": test_predicted,\n    \"phase\": \"dev\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T09:39:20.238374Z","iopub.execute_input":"2024-11-04T09:39:20.238720Z","iopub.status.idle":"2024-11-04T09:39:20.247524Z","shell.execute_reply.started":"2024-11-04T09:39:20.238690Z","shell.execute_reply":"2024-11-04T09:39:20.246644Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"\nwith open('results.json', 'w') as fp:\n    json.dump(result_json, fp,ensure_ascii=True,indent=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T09:39:20.248685Z","iopub.execute_input":"2024-11-04T09:39:20.248956Z","iopub.status.idle":"2024-11-04T09:39:20.261363Z","shell.execute_reply.started":"2024-11-04T09:39:20.248933Z","shell.execute_reply":"2024-11-04T09:39:20.260504Z"}},"outputs":[],"execution_count":79},{"cell_type":"markdown","source":"# Finetune for classification task","metadata":{}}]}