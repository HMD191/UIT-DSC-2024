{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9571267,"sourceType":"datasetVersion","datasetId":5834049},{"sourceId":9660707,"sourceType":"datasetVersion","datasetId":5902254},{"sourceId":9774475,"sourceType":"datasetVersion","datasetId":5987472},{"sourceId":9793891,"sourceType":"datasetVersion","datasetId":5953272},{"sourceId":9809037,"sourceType":"datasetVersion","datasetId":6012834}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Import Libraries and Load Dataset","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:27:09.117560Z","iopub.execute_input":"2024-11-05T14:27:09.117910Z","iopub.status.idle":"2024-11-05T14:27:21.602054Z","shell.execute_reply.started":"2024-11-05T14:27:09.117883Z","shell.execute_reply":"2024-11-05T14:27:21.600654Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import json\nimport gdown\ntrain_json = json.load(open('/kaggle/input/dsc24-vimmsd/vimmsd-train.json', encoding='utf-8'))\ndev_json = json.load(open('/kaggle/input/dsc24-vimmsd/vimmsd-public-test.json', encoding='utf-8'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:27:21.604463Z","iopub.execute_input":"2024-11-05T14:27:21.604837Z","iopub.status.idle":"2024-11-05T14:27:22.089054Z","shell.execute_reply.started":"2024-11-05T14:27:21.604803Z","shell.execute_reply":"2024-11-05T14:27:22.087586Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch.nn.functional import normalize\nfrom tqdm.notebook import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:13:40.530429Z","iopub.execute_input":"2024-11-05T15:13:40.531016Z","iopub.status.idle":"2024-11-05T15:13:40.535647Z","shell.execute_reply.started":"2024-11-05T15:13:40.530982Z","shell.execute_reply":"2024-11-05T15:13:40.534556Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"\nvisual_embeds = torch.load('/kaggle/input/dsc-visual-embeddings/visual_embeds.pt')\n# img_w = torch.load('/kaggle/input/lovecat-beitv2-b-p/beitv2-b-p.pt') # already-saved features\nlen(visual_embeds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:27:22.090915Z","iopub.execute_input":"2024-11-05T14:27:22.091710Z","iopub.status.idle":"2024-11-05T14:28:00.566126Z","shell.execute_reply.started":"2024-11-05T14:27:22.091664Z","shell.execute_reply":"2024-11-05T14:28:00.565174Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"12218"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"visual_embeds['ac7931bb887ad853b41675f07595bf04469970d1b099ffc8806a4ceaac7d7940.jpg'].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:28:00.568791Z","iopub.execute_input":"2024-11-05T14:28:00.569587Z","iopub.status.idle":"2024-11-05T14:28:00.575418Z","shell.execute_reply.started":"2024-11-05T14:28:00.569556Z","shell.execute_reply":"2024-11-05T14:28:00.574348Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"torch.Size([100, 1024])"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nfrom transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom transformers import VisualBertModel, VisualBertConfig\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:25:12.030266Z","iopub.execute_input":"2024-11-05T15:25:12.031111Z","iopub.status.idle":"2024-11-05T15:25:12.036732Z","shell.execute_reply.started":"2024-11-05T15:25:12.031081Z","shell.execute_reply":"2024-11-05T15:25:12.035773Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"class Config:\n   def __init__(self, random_seed = 42, max_len = 450, n_epochs = 2, batch_size = 8, lrate=2.5e-5,\n                n_warmup_steps=400, warmup_ratio=0.05,\n                visual_embedding_dim=1024, visual_model_name = 'uclanlp/visualbert-vqa-coco-pre',\n                classes = ['not-sarcasm', 'text-sarcasm', 'image-sarcasm', 'multi-sarcasm']):\n       self.random_seed = random_seed\n       self.max_len = max_len\n       self.n_classes = len(classes)\n       self.classes = classes\n       self.n_epochs = n_epochs\n       self.batch_size = batch_size\n       self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n       self.n_warmup_steps = n_warmup_steps\n       self.warmup_ratio = warmup_ratio\n       self.visual_embedding_dim = visual_embedding_dim\n       self.visual_model_name = visual_model_name\n       self.n_training_steps = n_epochs * 9724 // batch_size\n       self.lrate = lrate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:28:12.237381Z","iopub.execute_input":"2024-11-05T14:28:12.237718Z","iopub.status.idle":"2024-11-05T14:28:12.245710Z","shell.execute_reply.started":"2024-11-05T14:28:12.237692Z","shell.execute_reply":"2024-11-05T14:28:12.244670Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import random\n\nimport numpy as np\n\nimport torch\n\ndef set_SEED():\n    SEED = 42\n    random.seed(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.enabled = False\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\nset_SEED()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:28:12.246753Z","iopub.execute_input":"2024-11-05T14:28:12.247036Z","iopub.status.idle":"2024-11-05T14:28:12.277579Z","shell.execute_reply.started":"2024-11-05T14:28:12.247014Z","shell.execute_reply":"2024-11-05T14:28:12.276794Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:29:17.065030Z","iopub.execute_input":"2024-11-05T14:29:17.066023Z","iopub.status.idle":"2024-11-05T14:29:17.070889Z","shell.execute_reply.started":"2024-11-05T14:29:17.065981Z","shell.execute_reply":"2024-11-05T14:29:17.069808Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class MemesDataset(Dataset):\n    '''Wrap the tokenization process in a PyTorch Dataset, along with converting the labels to tensors'''\n    def __init__(self, data: pd.DataFrame, tokenizer: BertTokenizer, config: Config, visual_embeds):\n        self.tokenizer = tokenizer\n        self.data = data\n        self.max_len = config.max_len\n        self.visual_embeds = visual_embeds\n        self.classes = config.classes\n\n        # One-hot encode the labels\n        for class_name in self.classes:\n            self.data[class_name] = self.data['label'].apply(lambda x: 1 if x == class_name else 0)\n        self.data[self.classes] = self.data[self.classes].astype('int8')\n        print(self.data[self.classes].head())\n    \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n\n        data_row = self.data.iloc[index]\n        text = data_row.caption\n        labels = data_row[self.classes].values.astype(int)\n        image_id = data_row['image_id']\n\n        tokens = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding=\"max_length\",\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        input_ids = tokens[\"input_ids\"].flatten()\n        attention_mask = tokens[\"attention_mask\"].flatten()\n\n        visual_embedding = self.visual_embeds[image_id].to('cpu')\n        visual_attention_mask = torch.ones(visual_embedding.shape[:-1], dtype=torch.float)\n        visual_token_type_ids = torch.ones(visual_embedding.shape[:-1], dtype=torch.long)\n\n        return dict(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            visual_embedding=visual_embedding,\n            visual_attention_mask=visual_attention_mask,\n            visual_token_type_ids=visual_token_type_ids,\n            labels=torch.tensor(labels, dtype=torch.long)\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:50:55.576799Z","iopub.execute_input":"2024-11-05T14:50:55.577573Z","iopub.status.idle":"2024-11-05T14:50:55.588936Z","shell.execute_reply.started":"2024-11-05T14:50:55.577541Z","shell.execute_reply":"2024-11-05T14:50:55.587920Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"## Prepare datasets","metadata":{}},{"cell_type":"code","source":"emoji_file_path = '/kaggle/input/datasets-preprocesing/emoji_to_vietnamese.json'\nstopword_path = '/kaggle/input/datasets-preprocesing/vietnamese-stopwords.txt'\n\ndef load_resources(stopword_path, emoji_file_path):\n    # Đọc stopword từ file txt\n    with open(stopword_path, 'r', encoding='utf-8') as f:\n        stopwords = set(f.read().splitlines())\n\n    # Đọc emoji từ file JSON\n    with open(emoji_file_path, 'r', encoding='utf-8') as emoji_file:\n        emoji_dict = json.load(emoji_file)\n\n    return stopwords, emoji_dict\n\nstopwords, emoji_dict = load_resources(stopword_path, emoji_file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:29:18.834262Z","iopub.execute_input":"2024-11-05T14:29:18.834628Z","iopub.status.idle":"2024-11-05T14:29:18.850620Z","shell.execute_reply.started":"2024-11-05T14:29:18.834602Z","shell.execute_reply":"2024-11-05T14:29:18.849391Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.DataFrame(train_json).T\ntest_df = pd.DataFrame(dev_json).T # public test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:29:20.420464Z","iopub.execute_input":"2024-11-05T14:29:20.420792Z","iopub.status.idle":"2024-11-05T14:29:20.884762Z","shell.execute_reply.started":"2024-11-05T14:29:20.420770Z","shell.execute_reply":"2024-11-05T14:29:20.883946Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_df['image_id'] = train_df['image'].astype(str)\ntest_df['image_id'] = test_df['image'].astype(str)\n\ntrain_df['caption'] = train_df['caption'].astype(str)\ntest_df['caption'] = test_df['caption'].astype(str)\n\ntrain_df['label'] = train_df['label'].astype(str)\ntest_df['label'] = test_df['label'].astype(str)\n\ntrain_df.drop(columns=['image'], inplace=True)\ntest_df.drop(columns=['image'], inplace=True)\n\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:29:21.193325Z","iopub.execute_input":"2024-11-05T14:29:21.193686Z","iopub.status.idle":"2024-11-05T14:29:21.228968Z","shell.execute_reply.started":"2024-11-05T14:29:21.193658Z","shell.execute_reply":"2024-11-05T14:29:21.228066Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                             caption          label  \\\n0            Cô ấy trên mạng vs cô ấy ngoài đời =)))  multi-sarcasm   \n1    Người tâm linh giao tiếp với người thực tế :)))    not-sarcasm   \n2  Hình như Trăng hôm nay đẹp quá mọi người ạ! 😃 ...  multi-sarcasm   \n3  MỌI NGƯỜI NGHĨ SAO VỀ PHÁT BIỂU CỦA SHARK VIỆT...    not-sarcasm   \n4        2 tay hai nàng chứ việc gì phải lệ hai hàng  multi-sarcasm   \n\n                                            image_id  \n0  8ae451edcd8ebf697f8763ece249115813149c55733bf8...  \n1  35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...  \n2  316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...  \n3  8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...  \n4  e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>label</th>\n      <th>image_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cô ấy trên mạng vs cô ấy ngoài đời =)))</td>\n      <td>multi-sarcasm</td>\n      <td>8ae451edcd8ebf697f8763ece249115813149c55733bf8...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Người tâm linh giao tiếp với người thực tế :)))</td>\n      <td>not-sarcasm</td>\n      <td>35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hình như Trăng hôm nay đẹp quá mọi người ạ! 😃 ...</td>\n      <td>multi-sarcasm</td>\n      <td>316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MỌI NGƯỜI NGHĨ SAO VỀ PHÁT BIỂU CỦA SHARK VIỆT...</td>\n      <td>not-sarcasm</td>\n      <td>8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2 tay hai nàng chứ việc gì phải lệ hai hàng</td>\n      <td>multi-sarcasm</td>\n      <td>e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"### Features enrichment","metadata":{}},{"cell_type":"code","source":"!gdown 1q7_-PEQQ6IR3Ortz45vEiSiOnweRJ40H # cap train\n!gdown 1wldmw8IJgX-nK2_yfo8fLx55KfWGIZhp # cap dev ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:29:23.025037Z","iopub.execute_input":"2024-11-05T14:29:23.025424Z","iopub.status.idle":"2024-11-05T14:29:39.663871Z","shell.execute_reply.started":"2024-11-05T14:29:23.025367Z","shell.execute_reply":"2024-11-05T14:29:39.662740Z"}},"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1q7_-PEQQ6IR3Ortz45vEiSiOnweRJ40H\nTo: /kaggle/working/vi_train_captions.json\n100%|███████████████████████████████████████| 11.3M/11.3M [00:00<00:00, 217MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1wldmw8IJgX-nK2_yfo8fLx55KfWGIZhp\nTo: /kaggle/working/vi_dev_captions.json\n100%|███████████████████████████████████████| 1.14M/1.14M [00:00<00:00, 126MB/s]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!gdown 1AnM0RUMfyGYWaiUgafufEKMjB8zo5dUt # object reg train\n!gdown 1sk2vJutRJLCUwQ6ZKJQeYFKpvdkjUiBs # object reg dev","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:29:39.666262Z","iopub.execute_input":"2024-11-05T14:29:39.666696Z","iopub.status.idle":"2024-11-05T14:29:50.268431Z","shell.execute_reply.started":"2024-11-05T14:29:39.666658Z","shell.execute_reply":"2024-11-05T14:29:50.267325Z"}},"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1AnM0RUMfyGYWaiUgafufEKMjB8zo5dUt\nTo: /kaggle/working/objects-recognition-train.json\n100%|███████████████████████████████████████| 2.49M/2.49M [00:00<00:00, 178MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1sk2vJutRJLCUwQ6ZKJQeYFKpvdkjUiBs\nTo: /kaggle/working/objects-recognition-dev.json\n100%|█████████████████████████████████████████| 317k/317k [00:00<00:00, 106MB/s]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!gdown 1nh3y-lXq2CEc_rwzeTqGIU69VZA4eVEn # OCR dev\n!gdown 1YSn-dWwprc0nhOgRUIj5aFPaW9lxKWZT","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:29:50.270247Z","iopub.execute_input":"2024-11-05T14:29:50.270676Z","iopub.status.idle":"2024-11-05T14:30:00.239613Z","shell.execute_reply.started":"2024-11-05T14:29:50.270638Z","shell.execute_reply":"2024-11-05T14:30:00.238444Z"}},"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1nh3y-lXq2CEc_rwzeTqGIU69VZA4eVEn\nTo: /kaggle/working/ocr-results-dev.json\n100%|████████████████████████████████████████| 669k/669k [00:00<00:00, 98.8MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1YSn-dWwprc0nhOgRUIj5aFPaW9lxKWZT\nTo: /kaggle/working/ocr-results-train.json\n100%|███████████████████████████████████████| 4.06M/4.06M [00:00<00:00, 204MB/s]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"\n# Open JSON files with utf-8 encoding to handle non-ASCII characters\nwith open('/kaggle/working/vi_train_captions.json', encoding='utf-8') as f:\n    cap_train = json.load(f)\n\nwith open('/kaggle/working/vi_dev_captions.json', encoding='utf-8') as f:\n    cap_test = json.load(f)\n\nwith open('/kaggle/working/objects-recognition-train.json', encoding='utf-8') as f:\n    obj_train = json.load(f)\n\nwith open('/kaggle/working/objects-recognition-dev.json', encoding='utf-8') as f:\n    obj_test = json.load(f)\n\nwith open('/kaggle/working/ocr-results-dev.json', encoding='utf-8') as f:\n    ocr_test = json.load(f)\n\nwith open('/kaggle/working/ocr-results-train.json', encoding='utf-8') as f:\n    ocr_train = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:00.242210Z","iopub.execute_input":"2024-11-05T14:30:00.242553Z","iopub.status.idle":"2024-11-05T14:30:00.427444Z","shell.execute_reply.started":"2024-11-05T14:30:00.242524Z","shell.execute_reply":"2024-11-05T14:30:00.426368Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def json_to_df(json):\n    df = pd.DataFrame(json)\n    df['image_id'] = df['image'].astype(str)\n    df.drop(columns=['image'], inplace=True)\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:00.428849Z","iopub.execute_input":"2024-11-05T14:30:00.429240Z","iopub.status.idle":"2024-11-05T14:30:00.435251Z","shell.execute_reply.started":"2024-11-05T14:30:00.429204Z","shell.execute_reply":"2024-11-05T14:30:00.434139Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"for item in ocr_train:\n    item[\"OCR\"] = \", \".join(item[\"OCR\"])\nfor item in ocr_test:\n    item[\"OCR\"] = \", \".join(item[\"OCR\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:00.436503Z","iopub.execute_input":"2024-11-05T14:30:00.436824Z","iopub.status.idle":"2024-11-05T14:30:00.459990Z","shell.execute_reply.started":"2024-11-05T14:30:00.436798Z","shell.execute_reply":"2024-11-05T14:30:00.459242Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"cap_test_df = json_to_df(cap_test)\n\ncap_train_df = json_to_df(cap_train)\n\nobj_train_df = json_to_df(obj_train)\n\nobj_test_df = json_to_df(obj_test)\n\nocr_train_df = json_to_df(ocr_train)\n\nocr_test_df = json_to_df(ocr_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:00.461021Z","iopub.execute_input":"2024-11-05T14:30:00.461335Z","iopub.status.idle":"2024-11-05T14:30:00.513816Z","shell.execute_reply.started":"2024-11-05T14:30:00.461299Z","shell.execute_reply":"2024-11-05T14:30:00.512985Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"obj_train_df['object_recognition'] = obj_train_df['object_recognition'].apply(lambda x: \"Trong hình có \" + x + \". \" if len(x) > 0 else \"\")\nobj_test_df['object_recognition'] = obj_test_df['object_recognition'].apply(lambda x: \"Trong hình có \" + x + \". \" if len(x) > 0 else \"\")\nobj_test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:00.514910Z","iopub.execute_input":"2024-11-05T14:30:00.515207Z","iopub.status.idle":"2024-11-05T14:30:00.536642Z","shell.execute_reply.started":"2024-11-05T14:30:00.515181Z","shell.execute_reply":"2024-11-05T14:30:00.535749Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                  object_recognition  \\\n0  Trong hình có người, đồ vật, phim hoạt hình, đ...   \n1  Trong hình có truyện, người, dải, phim hoạt hì...   \n2                       Trong hình có số, ghi, chữ.    \n3               Trong hình có diều, người, văn bản.    \n4  Trong hình có suv, xe thể, quảng cáo, xe hơi, ...   \n\n                                            image_id  \n0  2d06d8c77c741d001916199346cc112847e6bcf61b3dce...  \n1  c981f23fc77cebd06ea872ea2c0ff6ec43a9d2517366ed...  \n2  342c9a8f91adeacde0f2c26dee3e6b86861b43e948d10b...  \n3  2aa95c65c0a6444caff0657ed21e27fbc403af1727749a...  \n4  9d6ebb26087b8d6051f77ef7cbf3e9a0d750baa41b45d7...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>object_recognition</th>\n      <th>image_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Trong hình có người, đồ vật, phim hoạt hình, đ...</td>\n      <td>2d06d8c77c741d001916199346cc112847e6bcf61b3dce...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Trong hình có truyện, người, dải, phim hoạt hì...</td>\n      <td>c981f23fc77cebd06ea872ea2c0ff6ec43a9d2517366ed...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Trong hình có số, ghi, chữ.</td>\n      <td>342c9a8f91adeacde0f2c26dee3e6b86861b43e948d10b...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trong hình có diều, người, văn bản.</td>\n      <td>2aa95c65c0a6444caff0657ed21e27fbc403af1727749a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trong hình có suv, xe thể, quảng cáo, xe hơi, ...</td>\n      <td>9d6ebb26087b8d6051f77ef7cbf3e9a0d750baa41b45d7...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"ocr_train_df['OCR'] = ocr_train_df['OCR'].apply(lambda row: \"Chữ trong hình là \" + row + \". \" if len(row) > 0 else \"\")\nocr_test_df['OCR'] = ocr_test_df['OCR'].apply(lambda row: \"Chữ trong hình là \" + row + \". \" if len(row) > 0 else \"\")\n\n# cap_train_df['caption'] = cap_train_df['caption'].apply(lambda row: row[:150] if len(row) > 150 else row)\n# cap_test_df['caption'] = cap_test_df['caption'].apply(lambda row: row[:150] if len(row) > 150 else row)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:00.537789Z","iopub.execute_input":"2024-11-05T14:30:00.538078Z","iopub.status.idle":"2024-11-05T14:30:00.555699Z","shell.execute_reply.started":"2024-11-05T14:30:00.538053Z","shell.execute_reply":"2024-11-05T14:30:00.554830Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def enrich(df1, df2, add_field):\n    temp = df2.set_index('image_id')\n    \n    df1['caption'] = df1.apply(\n        lambda row: row['caption'] + ' ' + temp.loc[row['image_id'], add_field]\n        if row['image_id'] in temp.index else row['caption'], axis=1\n    )\n\n    return df1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:00.559679Z","iopub.execute_input":"2024-11-05T14:30:00.559945Z","iopub.status.idle":"2024-11-05T14:30:00.567529Z","shell.execute_reply.started":"2024-11-05T14:30:00.559922Z","shell.execute_reply":"2024-11-05T14:30:00.566718Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"train_df['caption'] = train_df['caption'].apply(lambda x: x[:150] if len(x) > 150 else x)\ntest_df['caption'] = test_df['caption'].apply(lambda x: x[:150] if len(x) > 150 else x)\n\ntrain_df = enrich(train_df, ocr_train_df, 'OCR')\ntest_df = enrich(test_df, ocr_test_df, 'OCR')\n\ntrain_df = enrich(train_df, cap_train_df, 'caption')\ntest_df = enrich(test_df, cap_test_df, 'caption')\n\n# train_df = enrich(train_df, obj_train_df, 'object_recognition')\n# test_df = enrich(test_df, obj_test_df, 'object_recognition')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:00.568492Z","iopub.execute_input":"2024-11-05T14:30:00.568753Z","iopub.status.idle":"2024-11-05T14:30:15.136869Z","shell.execute_reply.started":"2024-11-05T14:30:00.568730Z","shell.execute_reply":"2024-11-05T14:30:15.135842Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:15.138159Z","iopub.execute_input":"2024-11-05T14:30:15.138493Z","iopub.status.idle":"2024-11-05T14:30:15.148480Z","shell.execute_reply.started":"2024-11-05T14:30:15.138467Z","shell.execute_reply":"2024-11-05T14:30:15.147497Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                             caption          label  \\\n0  Cô ấy trên mạng vs cô ấy ngoài đời =)))  Bức ả...  multi-sarcasm   \n1  Người tâm linh giao tiếp với người thực tế :))...    not-sarcasm   \n2  Hình như Trăng hôm nay đẹp quá mọi người ạ! 😃 ...  multi-sarcasm   \n3  MỌI NGƯỜI NGHĨ SAO VỀ PHÁT BIỂU CỦA SHARK VIỆT...    not-sarcasm   \n4  2 tay hai nàng chứ việc gì phải lệ hai hàng  H...  multi-sarcasm   \n\n                                            image_id  \n0  8ae451edcd8ebf697f8763ece249115813149c55733bf8...  \n1  35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...  \n2  316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...  \n3  8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...  \n4  e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>label</th>\n      <th>image_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cô ấy trên mạng vs cô ấy ngoài đời =)))  Bức ả...</td>\n      <td>multi-sarcasm</td>\n      <td>8ae451edcd8ebf697f8763ece249115813149c55733bf8...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Người tâm linh giao tiếp với người thực tế :))...</td>\n      <td>not-sarcasm</td>\n      <td>35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hình như Trăng hôm nay đẹp quá mọi người ạ! 😃 ...</td>\n      <td>multi-sarcasm</td>\n      <td>316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MỌI NGƯỜI NGHĨ SAO VỀ PHÁT BIỂU CỦA SHARK VIỆT...</td>\n      <td>not-sarcasm</td>\n      <td>8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2 tay hai nàng chứ việc gì phải lệ hai hàng  H...</td>\n      <td>multi-sarcasm</td>\n      <td>e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"### Text preprocessing","metadata":{}},{"cell_type":"code","source":"import re\ndef preprocess_text(text):\n    def remove_stopwords(text):\n        return text\n    def replace_emojis(text):\n        for emoji, description in emoji_dict.get('emoji', {}).items():\n            text = text.replace(emoji, description)  # Thay thế emoji bằng mô tả\n        return text\n\n    def replace_emoticons(text):\n        for emoticon, meaning in emoji_dict.get('biểu_tượng', {}).items():\n            emoticon_pattern = re.escape(emoticon) + r\"{1,}\"\n            text = re.sub(emoticon_pattern, meaning, text)\n        return text\n\n    def normalize_text(text):\n        text = text.lower()  # Chuyển thành chữ thường\n        text = re.sub(r'(?<=\\w)[\\/\\.\\-\\_,\\\\](?=\\w)', '', text)  # Loại bỏ dấu chấm hoặc gạch nối trong từ\n        return text\n\n    text = replace_emojis(text)       # Thay thế emoji\n    text = replace_emoticons(text)    # Thay thế biểu cảm\n    text = normalize_text(text)       # Chuẩn hóa văn bản\n    text = remove_stopwords(text)\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:15.149682Z","iopub.execute_input":"2024-11-05T14:30:15.150020Z","iopub.status.idle":"2024-11-05T14:30:15.160589Z","shell.execute_reply.started":"2024-11-05T14:30:15.149986Z","shell.execute_reply":"2024-11-05T14:30:15.159782Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"train_df['caption'] = train_df['caption'].astype(str)\ntest_df['caption'] = test_df['caption'].astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:15.161706Z","iopub.execute_input":"2024-11-05T14:30:15.162041Z","iopub.status.idle":"2024-11-05T14:30:15.256208Z","shell.execute_reply.started":"2024-11-05T14:30:15.162011Z","shell.execute_reply":"2024-11-05T14:30:15.255480Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"train_df['caption'] = train_df['caption'].apply(preprocess_text)\ntest_df['caption'] = test_df['caption'].apply(preprocess_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:15.257236Z","iopub.execute_input":"2024-11-05T14:30:15.257543Z","iopub.status.idle":"2024-11-05T14:30:16.984256Z","shell.execute_reply.started":"2024-11-05T14:30:15.257518Z","shell.execute_reply":"2024-11-05T14:30:16.983312Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"train_df['caption'].iloc[2003]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:16.985460Z","iopub.execute_input":"2024-11-05T14:30:16.985849Z","iopub.status.idle":"2024-11-05T14:30:16.992247Z","shell.execute_reply.started":"2024-11-05T14:30:16.985809Z","shell.execute_reply":"2024-11-05T14:30:16.991350Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'may mà gặp được tôi chữ trong hình là trờl olll_, làm sao thế này?!?, cậu bạn này đang vẽ dở, thỉ lăn đùng ra (o giật, sùl bọt mép!, nguy quá!, để tôl glúp!, 1.  hình ảnh mô tả một dải truyện tranh có một nhân vật hoạt hình và một người đang vẽ trên giá vẽ. nhân vật hoạt hình đang cầm một cây cọ vẽ trên một tay và một cây cọ trên tay kia, trong khi người đó đang ngồi trên giá vẽ với nụ cười trên môi. nội dung của hình ảnh có thể mang tính châm biếm, vì người đó đang cố gắng trêu chọc nỗ lực vẽ của người khác. tuy nhiên, nó cũng có thể mang tính giải trí, vì người đó dường như đang có một khoảng thời gian vui vẻ khi vẽ trên giá vẽ. nhìn chung, nội dung của hình ảnh có thể được coi là châm biếm hoặc giải trí, tùy thuộc vào quan điểm của người đó.'"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nX = train_df.drop(columns=['label'])  # Features\ny = train_df['label']  # Labels\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n\ntrain_df = pd.concat([X_train, y_train], axis=1)\nval_df = pd.concat([X_test, y_test], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:16.993278Z","iopub.execute_input":"2024-11-05T14:30:16.993621Z","iopub.status.idle":"2024-11-05T14:30:17.030247Z","shell.execute_reply.started":"2024-11-05T14:30:16.993595Z","shell.execute_reply":"2024-11-05T14:30:17.029414Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"print(train_df.shape, val_df.shape, test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:17.031533Z","iopub.execute_input":"2024-11-05T14:30:17.032262Z","iopub.status.idle":"2024-11-05T14:30:17.036745Z","shell.execute_reply.started":"2024-11-05T14:30:17.032228Z","shell.execute_reply":"2024-11-05T14:30:17.035873Z"}},"outputs":[{"name":"stdout","text":"(9724, 3) (1081, 3) (1413, 3)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## Create datasets","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nconfig = Config()\ntokenizer = AutoTokenizer.from_pretrained('uitnlp/visobert')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:17.037938Z","iopub.execute_input":"2024-11-05T14:30:17.038257Z","iopub.status.idle":"2024-11-05T14:30:18.412071Z","shell.execute_reply.started":"2024-11-05T14:30:17.038228Z","shell.execute_reply":"2024-11-05T14:30:18.411048Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2ea136a21e34007821acbeb6c06a951"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/471k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"feb622ebda0948b185783d38c6d7bee6"}},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"train_dataset = MemesDataset(train_df, tokenizer, config, visual_embeds)\nval_dataset = MemesDataset(val_df, tokenizer, config, visual_embeds)\ntest_dataset = MemesDataset(test_df, tokenizer, config, visual_embeds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:51:04.945225Z","iopub.execute_input":"2024-11-05T14:51:04.946189Z","iopub.status.idle":"2024-11-05T14:51:05.017206Z","shell.execute_reply.started":"2024-11-05T14:51:04.946148Z","shell.execute_reply":"2024-11-05T14:51:05.016087Z"}},"outputs":[{"name":"stdout","text":"       not-sarcasm  text-sarcasm  image-sarcasm  multi-sarcasm\n4004             0             0              0              1\n10369            0             0              0              1\n1157             1             0              0              0\n6181             1             0              0              0\n3987             1             0              0              0\n      not-sarcasm  text-sarcasm  image-sarcasm  multi-sarcasm\n5129            1             0              0              0\n7471            0             0              0              1\n2846            0             0              0              1\n1643            1             0              0              0\n3796            1             0              0              0\n   not-sarcasm  text-sarcasm  image-sarcasm  multi-sarcasm\n0            0             0              0              0\n1            0             0              0              0\n2            0             0              0              0\n3            0             0              0              0\n4            0             0              0              0\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:30:18.476995Z","iopub.execute_input":"2024-11-05T14:30:18.478642Z","iopub.status.idle":"2024-11-05T14:30:18.483145Z","shell.execute_reply.started":"2024-11-05T14:30:18.478615Z","shell.execute_reply":"2024-11-05T14:30:18.482397Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:48:48.929966Z","iopub.execute_input":"2024-11-05T14:48:48.930414Z","iopub.status.idle":"2024-11-05T14:48:49.316245Z","shell.execute_reply.started":"2024-11-05T14:48:48.930364Z","shell.execute_reply":"2024-11-05T14:48:49.315342Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"64"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class MemesClassifier(pl.LightningModule):\n  '''Wrap the training of VisualBERT model to classify memes'''\n\n  def __init__(self, config: Config):\n    super().__init__()\n    self.configuration = VisualBertConfig.from_pretrained(config.visual_model_name, visual_embedding_dim=config.visual_embedding_dim)\n    self.model = VisualBertModel(self.configuration)\n    self.n_warmup_steps = config.n_warmup_steps\n    self.criterion = nn.CrossEntropyLoss()\n    self.dropout = nn.Dropout(0.2)\n    self.classifier = nn.Linear(self.model.config.hidden_size, config.n_classes)\n    self.n_training_steps = config.n_training_steps\n    self.lrate = config.lrate\n  \n  def forward(self, input_ids, attention_mask, visual_embeds, visual_attention_mask, visual_token_type_ids, labels=None):\n    output = self.model(input_ids=input_ids,\n                        attention_mask=attention_mask,\n                        visual_embeds=visual_embeds,\n                        visual_attention_mask=visual_attention_mask,\n                        visual_token_type_ids=visual_token_type_ids\n    )\n    \n    output = self.dropout(output.pooler_output)\n    output = self.classifier(output)\n\n    return output\n  \n  def training_step(self, batch, batch_idx):\n    input_ids = batch['input_ids'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    visual_embeds = batch['visual_embedding'].to(device)\n    visual_attention_mask = batch['visual_attention_mask'].to(device)\n    visual_token_type_ids = batch['visual_token_type_ids'].to(device)\n\n    labels = batch['labels'].type(torch.float).to(device)\n    \n    outputs = self(input_ids, attention_mask, visual_embeds, visual_attention_mask, visual_token_type_ids, labels)\n    loss = self.criterion(outputs, labels)\n    self.log('train_loss', loss, prog_bar=True, logger=True)\n\n    return {\"loss\":loss, 'predictions':outputs, 'labels':labels}\n\n  def validation_step(self, batch, batch_idx):\n    input_ids = batch['input_ids']\n    attention_mask = batch['attention_mask']\n    visual_embeds = batch['visual_embedding']\n    visual_attention_mask = batch['visual_attention_mask']\n    visual_token_type_ids = batch['visual_token_type_ids'].to(device)\n    labels = batch['labels'].type(torch.float).to(device)\n    \n    outputs = self(input_ids, attention_mask, visual_embeds, visual_attention_mask, visual_token_type_ids, labels)\n    loss = self.criterion(outputs, labels)\n    self.log('val_loss', loss, prog_bar=True, logger=True)\n\n    return loss\n  \n  def configure_optimizers(self):\n    optimizer = AdamW(self.parameters(), lr=self.lrate)\n\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=self.n_warmup_steps,\n        num_training_steps=self.n_training_steps\n    )\n\n    return dict(\n        optimizer=optimizer,\n        lr_scheduler=dict(\n            scheduler=scheduler,\n            interval='step'\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:48:53.526327Z","iopub.execute_input":"2024-11-05T14:48:53.526745Z","iopub.status.idle":"2024-11-05T14:48:53.541332Z","shell.execute_reply.started":"2024-11-05T14:48:53.526714Z","shell.execute_reply":"2024-11-05T14:48:53.540438Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_dataset, val_dataset, tokenizer, config, visual_embeds):\n    checkpoint_callback = ModelCheckpoint(\n        dirpath=\"checkpoints\",\n        filename=\"best-checkpoint\",\n        save_top_k=5,\n        verbose=True,\n        monitor=\"val_loss\",\n        mode=\"min\",\n    )\n    \n    logger = TensorBoardLogger(\"lightning_logs\", name=\"memes-text\")\n    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n\n    trainer = pl.Trainer(\n        logger=logger,\n        callbacks=[early_stopping_callback, checkpoint_callback],\n        max_epochs=config.n_epochs,\n        accelerator=\"auto\",\n        enable_progress_bar=True,\n    )\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size)\n\n    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:55:04.600474Z","iopub.execute_input":"2024-11-05T14:55:04.600859Z","iopub.status.idle":"2024-11-05T14:55:04.608763Z","shell.execute_reply.started":"2024-11-05T14:55:04.600831Z","shell.execute_reply":"2024-11-05T14:55:04.607802Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"def evaluate_model(test_dataset, checkpoint, tokenizer, config, visual_embeds):\n\n    trained_model = MemesClassifier.load_from_checkpoint(\n        checkpoint,\n        config=config\n    ).to(device)\n\n    trained_model.eval()\n\n    predictions = []\n    labels = []\n    for item in tqdm(test_dataset):\n        with torch.no_grad():\n            prediction = trained_model(\n                item[\"input_ids\"].unsqueeze(dim=0).to(device),\n                item[\"attention_mask\"].unsqueeze(dim=0).to(device),\n                item[\"visual_embedding\"].unsqueeze(dim=0).to(device),\n                item['visual_attention_mask'].unsqueeze(dim=0).to(device),\n                item['visual_token_type_ids'].unsqueeze(dim=0).to(device)\n            )\n        predictions.append(prediction.flatten())\n        labels.append(item[\"labels\"])\n    \n    predictions = torch.stack(predictions).detach().cpu()\n    labels = torch.stack(labels).detach().cpu()\n\n    _, preds = torch.max(predictions, dim=1)\n    _, labels = torch.max(labels, dim=1)\n    \n    f1_macro = f1_score(labels, preds , average=\"macro\")\n    f1_micro = f1_score(labels, preds , average=\"micro\")\n\n    return f1_macro, f1_micro","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:26:00.494637Z","iopub.execute_input":"2024-11-05T15:26:00.494992Z","iopub.status.idle":"2024-11-05T15:26:00.506409Z","shell.execute_reply.started":"2024-11-05T15:26:00.494966Z","shell.execute_reply":"2024-11-05T15:26:00.505441Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"model = MemesClassifier(config).to('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:48:56.189185Z","iopub.execute_input":"2024-11-05T14:48:56.190053Z","iopub.status.idle":"2024-11-05T14:48:58.320843Z","shell.execute_reply.started":"2024-11-05T14:48:56.190018Z","shell.execute_reply":"2024-11-05T14:48:58.320018Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1cb37a37ce847b5bebe8db7760ab027"}},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"train_model(\n    model=model, \n    train_dataset=train_dataset, \n    val_dataset=val_dataset,\n    tokenizer=tokenizer,\n    config = config,\n    visual_embeds=visual_embeds\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T14:55:08.606838Z","iopub.execute_input":"2024-11-05T14:55:08.607190Z","iopub.status.idle":"2024-11-05T15:13:40.528617Z","shell.execute_reply.started":"2024-11-05T14:55:08.607163Z","shell.execute_reply":"2024-11-05T15:13:40.527814Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c392bccf499840b28a364adceaba9caa"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  rank_zero_warn(\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  rank_zero_warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f05d4e5e4d2546c7a54e4e1de3d2e399"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5a2b3c336b541dda2fdd061c4cb3940"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e9f4aa271104993b0868a25e2736c00"}},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:25:16.813888Z","iopub.execute_input":"2024-11-05T15:25:16.814234Z","iopub.status.idle":"2024-11-05T15:25:17.181336Z","shell.execute_reply.started":"2024-11-05T15:25:16.814207Z","shell.execute_reply":"2024-11-05T15:25:17.180137Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"4797"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"f1_macro, f1_micro = evaluate_model(\n    val_dataset,\n    checkpoint='./checkpoints/best-checkpoint.ckpt',\n    tokenizer=tokenizer,\n    config=config,\n    visual_embeds=visual_embeds\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:26:21.588345Z","iopub.execute_input":"2024-11-05T15:26:21.589276Z","iopub.status.idle":"2024-11-05T15:26:46.341483Z","shell.execute_reply.started":"2024-11-05T15:26:21.589235Z","shell.execute_reply":"2024-11-05T15:26:46.340542Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1081 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c49c8bc9dcd491eafb6d2930ef37723"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_32/23147861.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, preds = torch.max(torch.tensor(predictions), dim=1)\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"print(f\"Evaluate on valid set: f1_macro={f1_macro}, f1_micro={f1_micro}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:27:28.564388Z","iopub.execute_input":"2024-11-05T15:27:28.565000Z","iopub.status.idle":"2024-11-05T15:27:28.569588Z","shell.execute_reply.started":"2024-11-05T15:27:28.564969Z","shell.execute_reply":"2024-11-05T15:27:28.568733Z"}},"outputs":[{"name":"stdout","text":"Evaluate on valid set: f1_macro=0.32361345104117534, f1_micro=0.6318223866790009\n","output_type":"stream"}],"execution_count":66},{"cell_type":"markdown","source":"# Load checkpoints and predict\n\n","metadata":{}},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:27:35.853585Z","iopub.execute_input":"2024-11-05T15:27:35.853924Z","iopub.status.idle":"2024-11-05T15:27:36.238429Z","shell.execute_reply.started":"2024-11-05T15:27:35.853899Z","shell.execute_reply":"2024-11-05T15:27:36.237427Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"4303"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"\ndef get_prediction(test_dataset, checkpoint, tokenizer, config, visual_embeds, batch_size=2):\n    # Create DataLoader\n    test_dataloader = DataLoader(\n        test_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n    )\n    \n    # Load and set model to evaluation mode\n    trained_model = MemesClassifier.load_from_checkpoint(\n        checkpoint,\n        config=config\n    ).to(device)\n    trained_model.eval()\n    \n    all_predictions = []\n    \n    # Process batches\n    for batch in tqdm(test_dataloader, desc=\"Getting predictions\"):\n        with torch.no_grad():\n            # Move batch to device\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            # Get predictions\n            predictions = trained_model(\n                batch[\"input_ids\"],\n                batch[\"attention_mask\"],\n                batch[\"visual_embedding\"],\n                batch[\"visual_attention_mask\"],\n                batch[\"visual_token_type_ids\"]\n            )\n            \n            # Move predictions to CPU\n            all_predictions.append(predictions.cpu())\n    \n    # Concatenate all predictions\n    predictions = torch.cat(all_predictions, dim=0)\n    \n    # Get probabilities and predicted classes\n    probabilities = torch.softmax(predictions, dim=1)\n    predicted_classes = torch.argmax(predictions, dim=1)\n    \n    # Convert to class labels\n    predicted_labels = [config.classes[idx.item()] for idx in predicted_classes]\n    \n    return predicted_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:27:36.783074Z","iopub.execute_input":"2024-11-05T15:27:36.783436Z","iopub.status.idle":"2024-11-05T15:27:36.792789Z","shell.execute_reply.started":"2024-11-05T15:27:36.783401Z","shell.execute_reply":"2024-11-05T15:27:36.791874Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"predictions = get_prediction(\n    test_dataset,\n    checkpoint='./checkpoints/best-checkpoint.ckpt',\n    tokenizer=tokenizer,\n    config=config,\n    visual_embeds=visual_embeds\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:28:54.556142Z","iopub.execute_input":"2024-11-05T15:28:54.556969Z","iopub.status.idle":"2024-11-05T15:29:27.183810Z","shell.execute_reply.started":"2024-11-05T15:28:54.556936Z","shell.execute_reply":"2024-11-05T15:29:27.182856Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Getting predictions:   0%|          | 0/707 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4db6832094a140518545ed31d3c86795"}},"metadata":{}}],"execution_count":74},{"cell_type":"code","source":"len(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:29:27.186278Z","iopub.execute_input":"2024-11-05T15:29:27.186696Z","iopub.status.idle":"2024-11-05T15:29:27.193879Z","shell.execute_reply.started":"2024-11-05T15:29:27.186661Z","shell.execute_reply":"2024-11-05T15:29:27.192863Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"1413"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"\ntest_predicted = {k:i for k,i in zip(dev_json.keys(),predictions)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:29:27.195202Z","iopub.execute_input":"2024-11-05T15:29:27.195568Z","iopub.status.idle":"2024-11-05T15:29:27.202792Z","shell.execute_reply.started":"2024-11-05T15:29:27.195535Z","shell.execute_reply":"2024-11-05T15:29:27.201840Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"result_json = {\n    \"results\": test_predicted,\n    \"phase\": \"dev\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:29:27.204853Z","iopub.execute_input":"2024-11-05T15:29:27.205657Z","iopub.status.idle":"2024-11-05T15:29:27.221302Z","shell.execute_reply.started":"2024-11-05T15:29:27.205622Z","shell.execute_reply":"2024-11-05T15:29:27.220404Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"\nwith open('results.json', 'w') as fp:\n    json.dump(result_json, fp,ensure_ascii=True,indent=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T15:29:27.222400Z","iopub.execute_input":"2024-11-05T15:29:27.222775Z","iopub.status.idle":"2024-11-05T15:29:27.232772Z","shell.execute_reply.started":"2024-11-05T15:29:27.222738Z","shell.execute_reply":"2024-11-05T15:29:27.231891Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}